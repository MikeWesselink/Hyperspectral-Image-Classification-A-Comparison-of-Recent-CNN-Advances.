{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1BgyV0cypQ1YlT0LAzUBsTpC1qduwj8yg","timestamp":1680363921156}],"authorship_tag":"ABX9TyOkayNWYDAavTfMmaXZSy3g"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["## -*- coding: utf-8 -*-\n","# @Auther   : Mingsong Li (lms-07)\n","# @Time     : 2022-Nov\n","# @Address  : Time Lab @ SDU\n","# @FileName : process_dl.py\n","# @Project  : CVSSN (HSIC), IEEE TCSVT\n","\n","# for IP, KSC, and UP data sets, main processing file for the involved deep learning models,\n","# i.e., ,\n","# ContextualNet, RSSAN, SSTN, SSAtt, SSAN, SSSAN, A2S2KResNet, and the proposed CVSSN\n","\n"],"metadata":{"id":"BrKQpn_RwoGW"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yq6wLy5lwgOD","executionInfo":{"status":"ok","timestamp":1680663768934,"user_tz":300,"elapsed":23789,"user":{"displayName":"Michael Wesselink","userId":"03807820748818897534"}},"outputId":"36f26fef-765a-414b-da54-83f146f5c36f"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["#Original code attributed above from https://github.com/lms-07/CVSSN\n","\n","#Edits by Mike Wesselink 3.27.23\n","\n","###############################\n","#Mike Wesselink CIS 631\n","\n","#Mount my google drive (Plan B)\n","from google.colab import drive\n","drive.mount('/content/drive/')"]},{"cell_type":"code","source":["#imports\n","\n","import os\n","import time\n","import torch\n","import random\n","import numpy as np\n","from sklearn import metrics\n","\n","!pip install thop\n","from thop import profile\n","\n","#import spectral\n","!pip install spectral\n","from spectral import *\n","\n","import sys\n","\n","py_file_location = \"/content/drive/MyDrive/Colab Notebooks/CIS 631 Final Project/CVSSN-main\"\n","sys.path.append(os.path.abspath(py_file_location))\n","\n","import utils.evaluation as evaluation\n","import utils.data_load_operate as data_load_operate\n","import visual.cls_map_visual as cls_visual\n","\n","import model.ContextualNet as ContextualNet\n","import model.RSSAN as RSSAN\n","import model.SSTN as SSTN\n","import model.SSAtt as SSAtt\n","import model.A2S2KResNet as A2S2KResNet\n","import model.CVSSN as CVSSN\n","import model.SSAN as SSAN\n","import model.SSSAN as SSSAN\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3qGmG6xcwg1h","executionInfo":{"status":"ok","timestamp":1680663793462,"user_tz":300,"elapsed":24539,"user":{"displayName":"Michael Wesselink","userId":"03807820748818897534"}},"outputId":"778183eb-2f07-4f79-9845-7666735fd589"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from thop) (2.0.0+cu118)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->thop) (2.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->thop) (4.5.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->thop) (3.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->thop) (3.10.7)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->thop) (1.11.1)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->thop) (3.0)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->thop) (16.0.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->thop) (3.25.2)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->thop) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->thop) (1.3.0)\n","Installing collected packages: thop\n","Successfully installed thop-0.1.1.post2209072238\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spectral\n","  Downloading spectral-0.23.1-py3-none-any.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 KB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from spectral) (1.22.4)\n","Installing collected packages: spectral\n","Successfully installed spectral-0.23.1\n"]}]},{"cell_type":"code","source":["#SET UP MODEL INFO\n","\n","time_current = time.strftime(\"%y-%m-%d-%H.%M\", time.localtime())\n","\n","# random seed setting\n","seed = 20\n","\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)  # Numpy module.\n","random.seed(seed)  # Python random module.\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","###                 0             1       2       3        4        5         6             7\n","model_list = ['ContextualNet', 'RSSAN', 'SSTN', 'SSAN', 'SSSAN', 'SSAtt', 'A2S2KResNet', 'CVSSN']\n","\n","model_flag = 7\n","model_spa_set = {1, 2, 3, 5}\n","model_spe_set = {}\n","model_spa_spe_set = {4, 7}\n","model_3D_spa_set = {0, 6}\n","\n","model_3D_spa_flag = 0\n","\n","if model_flag in model_spa_set:\n","    model_type_flag = 1\n","    if model_flag in model_3D_spa_set:\n","        model_3D_spa_flag = 1\n","elif model_flag in model_spe_set:\n","    model_type_flag = 2\n","elif model_flag in model_spa_spe_set:\n","    model_type_flag = 3\n","\n","# 0-2\n","#data_set_name_list = ['IP', 'KSC', 'UP', 'HU_tif']\n","data_set_name_list = ['IP', 'KSC', 'UP', 'SALINAS']\n","data_set_name = data_set_name_list[2]  #test all 4 data sets by selecting position in data_set_name_list above?\n","\n","# seed_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  #\n","seed_list=[0,1,2,3,4]\n","# seed_list=[0,1,2] \n","# seed_list=[0,1]\n","#seed_list = [0]  \n","\n","# ratio=0.5\n","# ratio=1.0\n","# ratio=2.5\n","# ratio=5.0\n","# ratio=7.5\n","ratio = 10.0\n","patch_size = 9\n","patch_length = 4\n","\n","\n","###SET UP DATA PATH###\n","\n","#data_set_path = os.path.join(os.getcwd(), 'data')\n","data_set_path = '/content/drive/MyDrive/Colab Notebooks/CIS 631 Final Project/CVSSN-main/data'\n","\n","#results_save_path = \\\n","#    os.path.join(os.getcwd(), 'output/results', model_list[model_flag] + str(\"_\") +\n","#                 data_set_name + str(\"_\") + str(time_current) + str(\"_seed\") + str(seed) + str(\"_ratio\") + str(\n","#        ratio) + str(\"_patch_size\") + str(patch_size))\n","\n","results_save_path = \\\n","    os.path.join('/content/drive/MyDrive/Colab Notebooks/CIS 631 Final Project/CVSSN-main/output/results', model_list[model_flag] + str(\"_\") +\n","                data_set_name + str(\"_\") + str(time_current) + str(\"_seed\") + str(seed) + str(\"_ratio\") + str(\n","        ratio) + str(\"_patch_size\") + str(patch_size))\n","\n","\n","#cls_map_save_path = \\\n","#    os.path.join(os.path.join(os.getcwd(), 'output/cls_maps'), model_list[model_flag] + str(\"_\") +\n","#                 data_set_name + str(\"_\") + str(time_current) + str(\"_seed\") + str(seed)) + str(\"_ratio\") + str(ratio)\n","\n","cls_map_save_path = \\\n","    os.path.join(os.path.join('/content/drive/MyDrive/Colab Notebooks/CIS 631 Final Project/CVSSN-main/output/cls_maps'), model_list[model_flag] + str(\"_\") +\n","                 data_set_name + str(\"_\") + str(time_current) + str(\"_seed\") + str(seed)) + str(\"_ratio\") + str(ratio)\n","\n","if __name__ == '__main__':\n","\n","    torch.cuda.empty_cache()\n","\n","    data, gt = data_load_operate.load_data(data_set_name, data_set_path)\n","\n","    height, width, channels = data.shape\n","\n","    data = data_load_operate.standardization(data)\n","\n","    gt_reshape = gt.reshape(-1)\n","    height, width, channels = data.shape\n","    class_count = max(np.unique(gt))\n","\n","    flag_list = [0, 1]  # ratio or num\n","    ratio_list = [0.1, 0.01]  # [train_ratio,val_ratio]\n","    # ratio_list=[0.075,0.0075] # [train_ratio,val_ratio]\n","    # ratio_list=[0.05,0.005] # [train_ratio,val_ratio]\n","    # ratio_list=[0.0255,0.0025] # [train_ratio,val_ratio]\n","    # ratio_list=[0.01,0.001] # [train_ratio,val_ratio]\n","    # ratio_list=[0.005,0.0005] # [train_ratio,val_ratio]\n","    num_list = [45, 4]  # [train_num,val_num]\n","\n","    batch_size = 32\n","    max_epoch = 100\n","    learning_rate = 0.001\n","    loss = torch.nn.CrossEntropyLoss()\n","\n","    # data pad zero\n","    # data:[h,w,c]->data_padded:[h+2l,w+2l,c]\n","    data_padded = data_load_operate.data_pad_zero(data, patch_length)\n","    height_patched, width_patched, channels = data_padded.shape\n","\n","    OA_ALL = []\n","    AA_ALL = []\n","    KPP_ALL = []\n","    EACH_ACC_ALL = []\n","    Train_Time_ALL = []\n","    Test_Time_ALL = []\n","    CLASS_ACC = np.zeros([len(seed_list), class_count])\n","\n","    # data_total_index = np.arange(data.shape[0] * data.shape[1])  # For total sample cls_map.\n","\n","    for curr_seed in seed_list:\n","\n","        train_data_index, val_data_index, test_data_index, all_data_index = data_load_operate.sampling(ratio_list,\n","                                                                                                       num_list,\n","                                                                                                       gt_reshape,\n","                                                                                                       class_count,\n","                                                                                                       flag_list[0])\n","        index = (train_data_index, val_data_index, test_data_index)\n","        train_iter, test_iter, val_iter = data_load_operate.generate_iter_1 \\\n","            (data_padded, height, width, gt_reshape, index, patch_length, batch_size, model_type_flag,\n","             model_3D_spa_flag)\n","\n","\n","\n","        # load data for the cls map of all the labed samples\n","        # all_iter = data_load_operate.generate_iter_2(data_padded, height, width, gt_reshape, all_data_index,\n","        #                                              patch_length,\n","        #                                              batch_size, model_type_flag, model_3D_spa_flag)\n","        # load data for the cls map of the total samples\n","        # total_iter = data_load_operate.generate_iter_2(data_padded,height, width, gt_reshape, data_total_index, patch_length,\n","        #              25, model_type_flag, model_3D_spa_flag)\n","\n","        if model_flag == 0:\n","            net = ContextualNet.LeeEtAl(channels, class_count)\n","        elif model_flag == 1:\n","            net = RSSAN.RSSAN_net(in_shape=(channels, height_patched, width_patched), num_classes=class_count)\n","        elif model_flag == 2:\n","            net = SSTN.SSTN_AEAE(in_shape=(channels, height_patched, width_patched), num_classes=class_count)\n","        elif model_flag == 3:\n","            net = SSAN.SSAN(channels, patch_size, class_count)\n","        elif model_flag == 4:\n","            net = SSSAN.SSSAN(channels, class_count)\n","        elif model_flag == 5:\n","            net = SSAtt.Hang2020(channels, class_count)\n","        elif model_flag == 6:\n","            net = A2S2KResNet.S3KAIResNet(channels, class_count, 2)\n","        elif model_flag == 7:\n","            net = CVSSN.CVSSN_(channels, patch_size, patch_size, class_count)\n","\n","        # efficiency test, model complexity and computational cost\n","        # test_spe_input=torch.randn(1,channels) # for 1D model\n","        # test_input=torch.randn(1,patch_size,patch_size,channels) # for 2D model\n","        # test_input=torch.randn(1,1,patch_size,patch_size,channels) # for 3D model\n","        #\n","        # flops,para=profile(net,(test_input,test_spe_input))\n","        # flops,para=profile(net,(test_spe_input))\n","        # flops,para=profile(net,(test_input))\n","        #\n","        # print(\"para:{}\\n,flops:{}\".format(para,flops))\n","        # print(\"para(M):{:.3f},\\n flops(M):{:.2f}\".format(para/(1000**2),flops/(1000**2),))\n","\n","        net.to(device)\n","\n","        train_loss_list = [100]\n","        train_acc_list = [0]\n","        val_loss_list = [100]\n","        val_acc_list = [0]\n","        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","        best_loss = 99999\n","\n","        tic1 = time.perf_counter()\n","\n","        for epoch in range(max_epoch):\n","            train_acc_sum, trained_samples_counter = 0.0, 0\n","            batch_counter, train_loss_sum = 0, 0\n","            time_epoch = time.time()\n","\n","            if model_type_flag == 1:  # data for single spatial net\n","                for X_spa, y in train_iter:\n","                    X_spa, y = X_spa.to(device), y.to(device)\n","                    y_pred = net(X_spa)\n","\n","                    ls = loss(y_pred, y.long())\n","\n","                    optimizer.zero_grad()\n","                    ls.backward()\n","                    optimizer.step()\n","\n","                    train_loss_sum += ls.cpu().item()\n","                    train_acc_sum += (y_pred.argmax(dim=1) == y).sum().cpu().item()\n","                    trained_samples_counter += y.shape[0]\n","                    batch_counter += 1\n","                    epoch_first_iter = 0\n","            elif model_type_flag == 2:  # data for single spectral net\n","                for X_spe, y in train_iter:\n","                    X_spe, y = X_spe.to(device), y.to(device)\n","                    y_pred = net(X_spe)\n","\n","                    ls = loss(y_pred, y.long())\n","\n","                    optimizer.zero_grad()\n","                    ls.backward()\n","                    optimizer.step()\n","\n","                    train_loss_sum += ls.cpu().item()\n","                    train_acc_sum += (y_pred.argmax(dim=1) == y).sum().cpu().item()\n","                    trained_samples_counter += y.shape[0]\n","                    batch_counter += 1\n","                    epoch_first_iter = 0\n","            elif model_type_flag == 3:  # data for spectral-spatial net\n","                for X_spa, X_spe, y in train_iter:\n","                    X_spa, X_spe, y = X_spa.to(device), X_spe.to(device), y.to(device)\n","                    y_pred = net(X_spa, X_spe)\n","                    if model_flag == 10:\n","                        for i in range(len(y_pred)):\n","                            if i == 0:\n","                                ls = loss(y_pred[i], y.long())\n","                            if i > 0:\n","                                ls += loss(y_pred[i], y.long())\n","                    else:\n","\n","                        ls = loss(y_pred, y.long())\n","\n","                    optimizer.zero_grad()\n","                    ls.backward()\n","                    optimizer.step()\n","\n","                    train_loss_sum += ls.cpu().item()\n","                    train_acc_sum += (y_pred.argmax(dim=1) == y).sum().cpu().item()\n","                    trained_samples_counter += y.shape[0]\n","                    batch_counter += 1\n","                    epoch_first_iter = 0\n","\n","            val_acc, val_loss = evaluation.evaluate_OA(val_iter, net, loss, device, model_type_flag)\n","            val_loss_list.append(val_loss)\n","            val_acc_list.append(val_acc)\n","\n","            if val_loss < best_loss:\n","                best_loss = val_loss\n","                torch.save(net.state_dict(), results_save_path + \"_best_model.pt\")\n","                print('save model...')\n","\n","            torch.cuda.empty_cache()\n","\n","            train_loss_list.append(train_loss_sum)\n","            train_acc_list.append(train_acc_sum / trained_samples_counter)\n","\n","            print('epoch: %d, training_sampler_num: %d, batch_count: %.2f, train loss: %.6f, tarin loss sum: %.6f, '\n","                  'train acc: %.3f, train_acc_sum: %.1f, time: %.1f sec' %\n","                  (epoch + 1, trained_samples_counter, batch_counter, train_loss_sum / batch_counter, train_loss_sum,\n","                   train_acc_sum / trained_samples_counter, train_acc_sum, time.time() - time_epoch))\n","\n","        toc1 = time.perf_counter()\n","        print('Training stage finished:\\n epoch %d, loss %.4f, train acc %.3f, training time %.2f s'\n","              % (epoch + 1, train_loss_sum / batch_counter, train_acc_sum / trained_samples_counter, toc1 - tic1))\n","        training_time = toc1 - tic1\n","        Train_Time_ALL.append(training_time)\n","\n","        print(\"\\n\\n====================Starting evaluation for testing set.========================\\n\")\n","\n","        pred_test = []\n","        # torch.cuda.empty_cache()\n","        with torch.no_grad():\n","            # net.load_state_dict(torch.load(model_save_path+\"_best_model.pt\"))\n","            net.eval()\n","            train_acc_sum, samples_num_counter = 0.0, 0\n","            if model_type_flag == 1:  # data for single spatial net\n","                for X_spa, y in test_iter:\n","                    X_spa = X_spa.to(device)\n","                    y = y.to(device)\n","\n","                    tic2 = time.perf_counter()\n","                    y_pred = net(X_spa)\n","                    toc2 = time.perf_counter()\n","\n","                    pred_test.extend(np.array(y_pred.cpu().argmax(axis=1)))\n","            elif model_type_flag == 2:  # data for single spectral net\n","                for X_spe, y in test_iter:\n","                    X_spe = X_spe.to(device)\n","                    y = y.to(device)\n","\n","                    tic2 = time.perf_counter()\n","                    y_pred = net(X_spe)\n","                    toc2 = time.perf_counter()\n","\n","                    pred_test.extend(np.array(y_pred.cpu().argmax(axis=1)))\n","            elif model_type_flag == 3:  # data for spectral-spatial net\n","                for X_spa, X_spe, y in test_iter:\n","                    X_spa = X_spa.to(device)\n","                    X_spe = X_spe.to(device)\n","                    y = y.to(device)\n","\n","                    tic2 = time.perf_counter()\n","                    y_pred = net(X_spa, X_spe)\n","                    toc2 = time.perf_counter()\n","\n","                    pred_test.extend(np.array(y_pred.cpu().argmax(axis=1)))\n","\n","            y_gt = gt_reshape[test_data_index] - 1\n","            OA = metrics.accuracy_score(y_gt, pred_test)\n","            confusion_matrix = metrics.confusion_matrix(pred_test, y_gt)\n","            print(\"confusion_matrix\\n{}\".format(confusion_matrix))\n","            ECA, AA = evaluation.AA_ECA(confusion_matrix)\n","            kappa = metrics.cohen_kappa_score(pred_test, y_gt)\n","            cls_report = evaluation.claification_report(y_gt, pred_test, data_set_name)\n","            print(\"classification_report\\n{}\".format(cls_report))\n","\n","            # Visualization for all the labeled samples and total the samples\n","            # sample_list1 = [all_iter, all_data_index]\n","            # sample_list2 = [total_iter]\n","\n","            # cls_visual.pred_cls_map_dl(sample_list1,net,gt,cls_map_save_path,model_type_flag)\n","            # cls_visual.pred_cls_map_dl(sample_list2, net, gt, cls_map_save_path,model_type_flag)\n","\n","            testing_time = toc2 - tic2\n","            Test_Time_ALL.append(testing_time)\n","\n","\n","            # Output infors\n","            f = open(results_save_path + '_results.txt', 'a+')\n","            str_results = '\\n======================' \\\n","                          + \" learning rate=\" + str(learning_rate) \\\n","                          + \" epochs=\" + str(max_epoch) \\\n","                          + \" train ratio=\" + str(ratio_list[0]) \\\n","                          + \" val ratio=\" + str(ratio_list[1]) \\\n","                          + \" ======================\" \\\n","                          + \"\\nOA=\" + str(OA) \\\n","                          + \"\\nAA=\" + str(AA) \\\n","                          + '\\nkpp=' + str(kappa) \\\n","                          + '\\nacc per class:' + str(ECA) \\\n","                          + \"\\ntrain time:\" + str(training_time) \\\n","                          + \"\\ntest time:\" + str(testing_time) + \"\\n\"\n","\n","            f.write(str_results)\n","            f.write('{}'.format(confusion_matrix))\n","            f.write('\\n\\n')\n","            f.write('{}'.format(cls_report))\n","            f.close()\n","\n","            OA_ALL.append(OA)\n","            AA_ALL.append(AA)\n","            KPP_ALL.append(kappa)\n","            EACH_ACC_ALL.append(ECA)\n","\n","        torch.cuda.empty_cache()\n","        del net, train_iter, test_iter, val_iter\n","        # del net, train_iter, test_iter, val_iter, all_iter\n","        # del net\n","\n","    OA_ALL = np.array(OA_ALL)\n","    AA_ALL = np.array(AA_ALL)\n","    KPP_ALL = np.array(KPP_ALL)\n","    EACH_ACC_ALL = np.array(EACH_ACC_ALL)\n","    Train_Time_ALL = np.array(Train_Time_ALL)\n","    Test_Time_ALL = np.array(Test_Time_ALL)\n","\n","    np.set_printoptions(precision=4)\n","    print(\"\\n====================Mean result of {} times runs =========================\".format(len(seed_list)))\n","    print('List of OA:', list(OA_ALL))\n","    print('List of AA:', list(AA_ALL))\n","    print('List of KPP:', list(KPP_ALL))\n","    print('OA=', round(np.mean(OA_ALL) * 100, 2), '+-', round(np.std(OA_ALL) * 100, 2))\n","    print('AA=', round(np.mean(AA_ALL) * 100, 2), '+-', round(np.std(AA_ALL) * 100, 2))\n","    print('Kpp=', round(np.mean(KPP_ALL) * 100, 2), '+-', round(np.std(KPP_ALL) * 100, 2))\n","    print('Acc per class=', np.round(np.mean(EACH_ACC_ALL, 0) * 100, decimals=2), '+-',\n","          np.round(np.std(EACH_ACC_ALL, 0) * 100, decimals=2))\n","\n","    print(\"Average training time=\", round(np.mean(Train_Time_ALL), 2), '+-', round(np.std(Train_Time_ALL), 3))\n","    print(\"Average testing time=\", round(np.mean(Test_Time_ALL) * 1000, 2), '+-',\n","          round(np.std(Test_Time_ALL) * 1000, 3))\n","\n","    # Output infors\n","    f = open(results_save_path + '_results.txt', 'a+')\n","    str_results = '\\n\\n***************Mean result of ' + str(len(seed_list)) + 'times runs ********************' \\\n","                  + '\\nList of OA:' + str(list(OA_ALL)) \\\n","                  + '\\nList of AA:' + str(list(AA_ALL)) \\\n","                  + '\\nList of KPP:' + str(list(KPP_ALL)) \\\n","                  + '\\nOA=' + str(round(np.mean(OA_ALL) * 100, 2)) + '+-' + str(round(np.std(OA_ALL) * 100, 2)) \\\n","                  + '\\nAA=' + str(round(np.mean(AA_ALL) * 100, 2)) + '+-' + str(round(np.std(AA_ALL) * 100, 2)) \\\n","                  + '\\nKpp=' + str(round(np.mean(KPP_ALL) * 100, 2)) + '+-' + str(round(np.std(KPP_ALL) * 100, 2)) \\\n","                  + '\\nAcc per class=\\n' + str(np.round(np.mean(EACH_ACC_ALL, 0) * 100, 2)) + '+-' + str(\n","        np.round(np.std(EACH_ACC_ALL, 0) * 100, 2)) \\\n","                  + \"\\nAverage training time=\" + str(np.round(np.mean(Train_Time_ALL), decimals=2)) + '+-' + str(\n","        np.round(np.std(Train_Time_ALL), decimals=3)) \\\n","                  + \"\\nAverage testing time=\" + str(np.round(np.mean(Test_Time_ALL) * 1000, decimals=2)) + '+-' + str(\n","        np.round(np.std(Test_Time_ALL) * 100, decimals=3))\n","    f.write(str_results)\n","    f.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ATgpQ1R56bW9","executionInfo":{"status":"ok","timestamp":1680664247079,"user_tz":300,"elapsed":453627,"user":{"displayName":"Michael Wesselink","userId":"03807820748818897534"}},"outputId":"e56149a2-3f30-4ed6-a6db-f79b2cbfdeb0"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["save model...\n","epoch: 1, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.412848, tarin loss sum: 55.321669, train acc: 0.878, train_acc_sum: 3751.0, time: 8.8 sec\n","save model...\n","epoch: 2, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.133703, tarin loss sum: 17.916187, train acc: 0.953, train_acc_sum: 4074.0, time: 0.8 sec\n","epoch: 3, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.063615, tarin loss sum: 8.524455, train acc: 0.978, train_acc_sum: 4179.0, time: 0.8 sec\n","epoch: 4, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.043112, tarin loss sum: 5.777039, train acc: 0.985, train_acc_sum: 4211.0, time: 0.8 sec\n","save model...\n","epoch: 5, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.051534, tarin loss sum: 6.905556, train acc: 0.982, train_acc_sum: 4197.0, time: 0.8 sec\n","epoch: 6, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.015728, tarin loss sum: 2.107510, train acc: 0.995, train_acc_sum: 4253.0, time: 0.8 sec\n","save model...\n","epoch: 7, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.007659, tarin loss sum: 1.026276, train acc: 0.998, train_acc_sum: 4263.0, time: 0.8 sec\n","epoch: 8, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.013876, tarin loss sum: 1.859391, train acc: 0.995, train_acc_sum: 4250.0, time: 0.9 sec\n","epoch: 9, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.082686, tarin loss sum: 11.079904, train acc: 0.977, train_acc_sum: 4176.0, time: 0.9 sec\n","epoch: 10, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.010403, tarin loss sum: 1.393967, train acc: 0.997, train_acc_sum: 4260.0, time: 0.8 sec\n","epoch: 11, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.042972, tarin loss sum: 5.758206, train acc: 0.988, train_acc_sum: 4221.0, time: 0.8 sec\n","epoch: 12, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.006704, tarin loss sum: 0.898276, train acc: 0.998, train_acc_sum: 4265.0, time: 0.8 sec\n","epoch: 13, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000847, tarin loss sum: 0.113542, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 14, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000218, tarin loss sum: 0.029259, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 15, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000143, tarin loss sum: 0.019195, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 16, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000113, tarin loss sum: 0.015203, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 17, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000087, tarin loss sum: 0.011616, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 18, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000073, tarin loss sum: 0.009840, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 19, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000060, tarin loss sum: 0.008083, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 20, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000054, tarin loss sum: 0.007255, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 21, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000045, tarin loss sum: 0.006069, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 22, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000041, tarin loss sum: 0.005501, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 23, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000035, tarin loss sum: 0.004713, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 24, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000032, tarin loss sum: 0.004275, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 25, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000029, tarin loss sum: 0.003844, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 26, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000025, tarin loss sum: 0.003407, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 27, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000023, tarin loss sum: 0.003025, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 28, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000020, tarin loss sum: 0.002667, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 29, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000019, tarin loss sum: 0.002492, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 30, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000016, tarin loss sum: 0.002194, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 31, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000015, tarin loss sum: 0.001976, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 32, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000013, tarin loss sum: 0.001804, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 33, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000012, tarin loss sum: 0.001667, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 34, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000011, tarin loss sum: 0.001518, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 35, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000010, tarin loss sum: 0.001406, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 36, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000009, tarin loss sum: 0.001263, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 37, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000009, tarin loss sum: 0.001158, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 38, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000008, tarin loss sum: 0.001079, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 39, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000007, tarin loss sum: 0.000981, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 40, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000007, tarin loss sum: 0.000894, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 41, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000006, tarin loss sum: 0.000828, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 42, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000006, tarin loss sum: 0.000764, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 43, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000005, tarin loss sum: 0.000700, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 44, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000005, tarin loss sum: 0.000654, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 45, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000600, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 46, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000541, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 47, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000507, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 48, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000466, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 49, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000428, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 50, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000400, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 51, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000375, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 52, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000334, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 53, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000326, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 54, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000292, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 55, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000265, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 56, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000247, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 57, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000235, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 58, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000217, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 59, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000200, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 60, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000182, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 61, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000171, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 62, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000154, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 63, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000150, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 64, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000138, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 65, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000126, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 66, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000116, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 67, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000106, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 68, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000100, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 69, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000091, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 70, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000085, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 71, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000078, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 72, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000073, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 73, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000068, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 74, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000063, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 75, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000061, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 76, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000055, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 77, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000051, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 78, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000047, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 79, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000044, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 80, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000042, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 81, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000037, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 82, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000034, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 83, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000031, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 84, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000030, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 85, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000029, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 86, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000025, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 87, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000023, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 88, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000022, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 89, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000020, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 90, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000019, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 91, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000017, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 92, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000016, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 93, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000015, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 94, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000014, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 95, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000013, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 96, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000013, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 97, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000018, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 98, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000012, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 99, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000011, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 100, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000010, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","Training stage finished:\n"," epoch 100, loss 0.0000, train acc 1.000, training time 88.86 s\n","\n","\n","====================Starting evaluation for testing set.========================\n","\n","confusion_matrix\n","[[ 5901     0     6     0     0     0     0     0     0]\n"," [    0 16599     0     0     0     0     0     0     0]\n"," [    0     0  1851     0     0     0     0     0     0]\n"," [    0     0     0  2723     0     0     0     0     0]\n"," [    0     0     0     0  1198     0     0     0     1]\n"," [    0     0     0     0     0  4477     0     0     0]\n"," [    0     0     0     0     0     0  1184     0     0]\n"," [    1     0    13     5     0     0     0  3278     0]\n"," [    0     0     0     0     0     0     0     0   843]]\n","                      precision    recall  f1-score   support\n","\n","             Asphalt       1.00      1.00      1.00      5902\n","             Meadows       1.00      1.00      1.00     16599\n","              Gravel       1.00      0.99      0.99      1870\n","               Trees       1.00      1.00      1.00      2728\n","Painted metal sheets       1.00      1.00      1.00      1198\n","           Bare Soil       1.00      1.00      1.00      4477\n","             Bitumen       1.00      1.00      1.00      1184\n","Self-Blocking Bricks       0.99      1.00      1.00      3278\n","             Shadows       1.00      1.00      1.00       844\n","\n","            accuracy                           1.00     38080\n","           macro avg       1.00      1.00      1.00     38080\n","        weighted avg       1.00      1.00      1.00     38080\n","\n","classification_report\n","                      precision    recall  f1-score   support\n","\n","             Asphalt       1.00      1.00      1.00      5902\n","             Meadows       1.00      1.00      1.00     16599\n","              Gravel       1.00      0.99      0.99      1870\n","               Trees       1.00      1.00      1.00      2728\n","Painted metal sheets       1.00      1.00      1.00      1198\n","           Bare Soil       1.00      1.00      1.00      4477\n","             Bitumen       1.00      1.00      1.00      1184\n","Self-Blocking Bricks       0.99      1.00      1.00      3278\n","             Shadows       1.00      1.00      1.00       844\n","\n","            accuracy                           1.00     38080\n","           macro avg       1.00      1.00      1.00     38080\n","        weighted avg       1.00      1.00      1.00     38080\n","\n","save model...\n","epoch: 1, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.394824, tarin loss sum: 52.906463, train acc: 0.874, train_acc_sum: 3736.0, time: 0.9 sec\n","save model...\n","epoch: 2, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.172582, tarin loss sum: 23.125972, train acc: 0.943, train_acc_sum: 4029.0, time: 0.8 sec\n","epoch: 3, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.067758, tarin loss sum: 9.079524, train acc: 0.979, train_acc_sum: 4184.0, time: 0.8 sec\n","save model...\n","epoch: 4, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.057424, tarin loss sum: 7.694826, train acc: 0.981, train_acc_sum: 4191.0, time: 0.9 sec\n","save model...\n","epoch: 5, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.023053, tarin loss sum: 3.089131, train acc: 0.993, train_acc_sum: 4241.0, time: 0.9 sec\n","epoch: 6, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.005759, tarin loss sum: 0.771709, train acc: 0.999, train_acc_sum: 4269.0, time: 0.9 sec\n","epoch: 7, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.002774, tarin loss sum: 0.371650, train acc: 1.000, train_acc_sum: 4271.0, time: 0.9 sec\n","epoch: 8, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000594, tarin loss sum: 0.079529, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","save model...\n","epoch: 9, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000304, tarin loss sum: 0.040730, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 10, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000234, tarin loss sum: 0.031290, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 11, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000627, tarin loss sum: 0.083965, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 12, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000270, tarin loss sum: 0.036230, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 13, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000127, tarin loss sum: 0.016971, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 14, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000092, tarin loss sum: 0.012261, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 15, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000074, tarin loss sum: 0.009857, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 16, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000058, tarin loss sum: 0.007709, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 17, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000053, tarin loss sum: 0.007150, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 18, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000043, tarin loss sum: 0.005759, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 19, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000043, tarin loss sum: 0.005777, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 20, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000037, tarin loss sum: 0.004963, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 21, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000031, tarin loss sum: 0.004127, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 22, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000028, tarin loss sum: 0.003746, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 23, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000024, tarin loss sum: 0.003238, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 24, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000023, tarin loss sum: 0.003026, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 25, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000020, tarin loss sum: 0.002630, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 26, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000019, tarin loss sum: 0.002508, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 27, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000016, tarin loss sum: 0.002165, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 28, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000019, tarin loss sum: 0.002549, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 29, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000015, tarin loss sum: 0.001980, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 30, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000013, tarin loss sum: 0.001693, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 31, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000011, tarin loss sum: 0.001501, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 32, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000010, tarin loss sum: 0.001312, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 33, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000009, tarin loss sum: 0.001266, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 34, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000008, tarin loss sum: 0.001111, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 35, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000008, tarin loss sum: 0.001006, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 36, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000007, tarin loss sum: 0.000947, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 37, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000006, tarin loss sum: 0.000844, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 38, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000006, tarin loss sum: 0.000807, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 39, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000006, tarin loss sum: 0.000744, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 40, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000005, tarin loss sum: 0.000678, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 41, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000005, tarin loss sum: 0.000636, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 42, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000554, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 43, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000523, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 44, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000482, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 45, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000438, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 46, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000407, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 47, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000375, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 48, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000341, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 49, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000324, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 50, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000304, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 51, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000264, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 52, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000240, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 53, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000222, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 54, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000216, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 55, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000188, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 56, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000178, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 57, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000163, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 58, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000148, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 59, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000139, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 60, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000132, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 61, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000118, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 62, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000113, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 63, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000102, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 64, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000094, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 65, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000085, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 66, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000082, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 67, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000075, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 68, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000069, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 69, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000063, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 70, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000058, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 71, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000053, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 72, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000051, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 73, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000046, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 74, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000043, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 75, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000039, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 76, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000037, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 77, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000034, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 78, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000034, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 79, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000029, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 80, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000027, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 81, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000025, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 82, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000023, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 83, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000021, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 84, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000020, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 85, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000018, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 86, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000017, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 87, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000015, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 88, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000015, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 89, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000014, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 90, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000013, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 91, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000011, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 92, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000011, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 93, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000010, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 94, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000010, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 95, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000009, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 96, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000008, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 97, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000008, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 98, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000007, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 99, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000006, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 100, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000006, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","Training stage finished:\n"," epoch 100, loss 0.0000, train acc 1.000, training time 81.52 s\n","\n","\n","====================Starting evaluation for testing set.========================\n","\n","confusion_matrix\n","[[ 5880     0     2     1     0     0     0     0     0]\n"," [    0 16599     0     1     0     2     0     0     0]\n"," [    1     0  1866     0     0     0     0     0     0]\n"," [    6     0     0  2722     0     0     0     0     0]\n"," [    0     0     0     0  1198     0     0     0     2]\n"," [    0     0     0     1     0  4475     0     0     0]\n"," [    0     0     0     0     0     0  1184     0     0]\n"," [   15     0     2     2     0     0     0  3278     0]\n"," [    0     0     0     1     0     0     0     0   842]]\n","                      precision    recall  f1-score   support\n","\n","             Asphalt       1.00      1.00      1.00      5902\n","             Meadows       1.00      1.00      1.00     16599\n","              Gravel       1.00      1.00      1.00      1870\n","               Trees       1.00      1.00      1.00      2728\n","Painted metal sheets       1.00      1.00      1.00      1198\n","           Bare Soil       1.00      1.00      1.00      4477\n","             Bitumen       1.00      1.00      1.00      1184\n","Self-Blocking Bricks       0.99      1.00      1.00      3278\n","             Shadows       1.00      1.00      1.00       844\n","\n","            accuracy                           1.00     38080\n","           macro avg       1.00      1.00      1.00     38080\n","        weighted avg       1.00      1.00      1.00     38080\n","\n","classification_report\n","                      precision    recall  f1-score   support\n","\n","             Asphalt       1.00      1.00      1.00      5902\n","             Meadows       1.00      1.00      1.00     16599\n","              Gravel       1.00      1.00      1.00      1870\n","               Trees       1.00      1.00      1.00      2728\n","Painted metal sheets       1.00      1.00      1.00      1198\n","           Bare Soil       1.00      1.00      1.00      4477\n","             Bitumen       1.00      1.00      1.00      1184\n","Self-Blocking Bricks       0.99      1.00      1.00      3278\n","             Shadows       1.00      1.00      1.00       844\n","\n","            accuracy                           1.00     38080\n","           macro avg       1.00      1.00      1.00     38080\n","        weighted avg       1.00      1.00      1.00     38080\n","\n","save model...\n","epoch: 1, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.412663, tarin loss sum: 55.296895, train acc: 0.874, train_acc_sum: 3733.0, time: 0.9 sec\n","save model...\n","epoch: 2, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.144855, tarin loss sum: 19.410592, train acc: 0.952, train_acc_sum: 4066.0, time: 0.8 sec\n","epoch: 3, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.059365, tarin loss sum: 7.954933, train acc: 0.980, train_acc_sum: 4188.0, time: 0.8 sec\n","save model...\n","epoch: 4, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.046147, tarin loss sum: 6.183666, train acc: 0.984, train_acc_sum: 4204.0, time: 0.8 sec\n","epoch: 5, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.016782, tarin loss sum: 2.248795, train acc: 0.994, train_acc_sum: 4247.0, time: 0.8 sec\n","save model...\n","epoch: 6, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.035856, tarin loss sum: 4.804678, train acc: 0.991, train_acc_sum: 4234.0, time: 0.8 sec\n","epoch: 7, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.036867, tarin loss sum: 4.940227, train acc: 0.989, train_acc_sum: 4228.0, time: 0.8 sec\n","epoch: 8, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.012271, tarin loss sum: 1.644301, train acc: 0.996, train_acc_sum: 4256.0, time: 0.8 sec\n","save model...\n","epoch: 9, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.027452, tarin loss sum: 3.678542, train acc: 0.991, train_acc_sum: 4236.0, time: 0.8 sec\n","epoch: 10, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.038125, tarin loss sum: 5.108784, train acc: 0.989, train_acc_sum: 4226.0, time: 0.8 sec\n","epoch: 11, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.008364, tarin loss sum: 1.120833, train acc: 0.998, train_acc_sum: 4264.0, time: 0.8 sec\n","epoch: 12, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000875, tarin loss sum: 0.117316, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 13, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.029205, tarin loss sum: 3.913526, train acc: 0.993, train_acc_sum: 4241.0, time: 0.8 sec\n","epoch: 14, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.030100, tarin loss sum: 4.033354, train acc: 0.989, train_acc_sum: 4227.0, time: 0.8 sec\n","epoch: 15, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000495, tarin loss sum: 0.066297, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 16, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000184, tarin loss sum: 0.024685, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 17, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000121, tarin loss sum: 0.016268, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 18, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000095, tarin loss sum: 0.012777, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 19, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000075, tarin loss sum: 0.010046, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 20, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000062, tarin loss sum: 0.008246, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 21, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000053, tarin loss sum: 0.007037, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 22, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000045, tarin loss sum: 0.005984, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 23, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000038, tarin loss sum: 0.005133, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 24, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000033, tarin loss sum: 0.004460, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 25, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000030, tarin loss sum: 0.004012, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 26, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000026, tarin loss sum: 0.003471, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 27, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000023, tarin loss sum: 0.003100, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 28, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000021, tarin loss sum: 0.002807, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 29, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000019, tarin loss sum: 0.002503, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 30, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000017, tarin loss sum: 0.002236, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 31, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000015, tarin loss sum: 0.002045, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 32, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000014, tarin loss sum: 0.001817, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 33, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000012, tarin loss sum: 0.001656, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 34, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000011, tarin loss sum: 0.001506, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 35, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000010, tarin loss sum: 0.001360, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 36, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000009, tarin loss sum: 0.001256, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 37, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000009, tarin loss sum: 0.001143, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 38, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000008, tarin loss sum: 0.001051, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 39, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000007, tarin loss sum: 0.000962, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 40, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000007, tarin loss sum: 0.000878, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 41, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000006, tarin loss sum: 0.000807, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 42, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000006, tarin loss sum: 0.000749, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 43, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000005, tarin loss sum: 0.000684, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 44, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000005, tarin loss sum: 0.000626, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 45, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000582, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 46, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000533, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 47, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000494, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 48, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000456, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 49, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000423, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 50, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000392, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 51, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000356, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 52, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000333, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 53, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000306, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 54, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000295, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 55, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000262, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 56, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000241, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 57, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000222, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 58, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000205, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 59, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000191, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 60, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000177, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 61, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000164, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 62, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000153, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 63, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000140, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 64, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000130, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 65, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000121, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 66, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000112, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 67, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000104, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 68, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000097, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 69, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000089, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 70, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000083, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 71, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000077, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 72, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000072, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 73, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000067, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 74, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000062, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 75, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000057, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 76, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000054, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 77, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000050, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 78, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000047, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 79, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000043, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 80, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000040, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 81, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000037, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 82, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000034, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 83, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000032, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 84, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000029, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 85, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000027, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 86, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000025, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 87, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000024, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 88, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000022, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 89, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000020, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 90, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000019, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 91, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000018, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 92, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000016, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 93, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000015, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 94, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000014, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 95, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000013, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 96, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000012, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 97, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000011, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 98, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000010, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 99, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000010, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 100, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000009, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","Training stage finished:\n"," epoch 100, loss 0.0000, train acc 1.000, training time 80.97 s\n","\n","\n","====================Starting evaluation for testing set.========================\n","\n","confusion_matrix\n","[[ 5896     0     1     0     0     0     0     2     0]\n"," [    0 16588     0     1     0     7     0     0     0]\n"," [    0     0  1861     0     0     0     0     0     0]\n"," [    0     1     0  2724     0     0     0     0     0]\n"," [    0     0     0     0  1198     0     0     0     1]\n"," [    0    10     0     3     0  4470     0     0     0]\n"," [    0     0     0     0     0     0  1184     0     0]\n"," [    6     0     8     0     0     0     0  3276     0]\n"," [    0     0     0     0     0     0     0     0   843]]\n","                      precision    recall  f1-score   support\n","\n","             Asphalt       1.00      1.00      1.00      5902\n","             Meadows       1.00      1.00      1.00     16599\n","              Gravel       1.00      1.00      1.00      1870\n","               Trees       1.00      1.00      1.00      2728\n","Painted metal sheets       1.00      1.00      1.00      1198\n","           Bare Soil       1.00      1.00      1.00      4477\n","             Bitumen       1.00      1.00      1.00      1184\n","Self-Blocking Bricks       1.00      1.00      1.00      3278\n","             Shadows       1.00      1.00      1.00       844\n","\n","            accuracy                           1.00     38080\n","           macro avg       1.00      1.00      1.00     38080\n","        weighted avg       1.00      1.00      1.00     38080\n","\n","classification_report\n","                      precision    recall  f1-score   support\n","\n","             Asphalt       1.00      1.00      1.00      5902\n","             Meadows       1.00      1.00      1.00     16599\n","              Gravel       1.00      1.00      1.00      1870\n","               Trees       1.00      1.00      1.00      2728\n","Painted metal sheets       1.00      1.00      1.00      1198\n","           Bare Soil       1.00      1.00      1.00      4477\n","             Bitumen       1.00      1.00      1.00      1184\n","Self-Blocking Bricks       1.00      1.00      1.00      3278\n","             Shadows       1.00      1.00      1.00       844\n","\n","            accuracy                           1.00     38080\n","           macro avg       1.00      1.00      1.00     38080\n","        weighted avg       1.00      1.00      1.00     38080\n","\n","save model...\n","epoch: 1, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.398803, tarin loss sum: 53.439568, train acc: 0.873, train_acc_sum: 3731.0, time: 0.9 sec\n","save model...\n","epoch: 2, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.127751, tarin loss sum: 17.118696, train acc: 0.950, train_acc_sum: 4061.0, time: 0.8 sec\n","save model...\n","epoch: 3, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.058951, tarin loss sum: 7.899456, train acc: 0.981, train_acc_sum: 4190.0, time: 0.8 sec\n","epoch: 4, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.052558, tarin loss sum: 7.042716, train acc: 0.980, train_acc_sum: 4189.0, time: 0.8 sec\n","epoch: 5, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.016362, tarin loss sum: 2.192463, train acc: 0.994, train_acc_sum: 4248.0, time: 0.8 sec\n","save model...\n","epoch: 6, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.004291, tarin loss sum: 0.574963, train acc: 1.000, train_acc_sum: 4271.0, time: 0.8 sec\n","save model...\n","epoch: 7, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.001106, tarin loss sum: 0.148146, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 8, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000528, tarin loss sum: 0.070809, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 9, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000247, tarin loss sum: 0.033139, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 10, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000200, tarin loss sum: 0.026783, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 11, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000136, tarin loss sum: 0.018285, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 12, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000119, tarin loss sum: 0.015912, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 13, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000097, tarin loss sum: 0.012961, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 14, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000077, tarin loss sum: 0.010377, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 15, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000067, tarin loss sum: 0.008996, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 16, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000056, tarin loss sum: 0.007500, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 17, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000050, tarin loss sum: 0.006740, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 18, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000043, tarin loss sum: 0.005724, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 19, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000037, tarin loss sum: 0.004986, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 20, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000034, tarin loss sum: 0.004494, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 21, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000030, tarin loss sum: 0.003962, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 22, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000026, tarin loss sum: 0.003506, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 23, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000024, tarin loss sum: 0.003184, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 24, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000020, tarin loss sum: 0.002715, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 25, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000018, tarin loss sum: 0.002425, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 26, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000017, tarin loss sum: 0.002302, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 27, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000015, tarin loss sum: 0.001961, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 28, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000014, tarin loss sum: 0.001890, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 29, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000012, tarin loss sum: 0.001637, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 30, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000011, tarin loss sum: 0.001465, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 31, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000010, tarin loss sum: 0.001375, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 32, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000009, tarin loss sum: 0.001196, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 33, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000008, tarin loss sum: 0.001112, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 34, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000007, tarin loss sum: 0.001002, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 35, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000007, tarin loss sum: 0.000919, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 36, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000006, tarin loss sum: 0.000851, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 37, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000006, tarin loss sum: 0.000788, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 38, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000005, tarin loss sum: 0.000697, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 39, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000005, tarin loss sum: 0.000626, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 40, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000566, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 41, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000537, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 42, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000481, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 43, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000455, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 44, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000412, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 45, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000377, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 46, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000341, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 47, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000314, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 48, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000290, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 49, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000263, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 50, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000253, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 51, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000227, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 52, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000207, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 53, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000195, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 54, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000182, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 55, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000162, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 56, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000145, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 57, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000143, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 58, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000128, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 59, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000115, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 60, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000107, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 61, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000101, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 62, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000092, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 63, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000083, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 64, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000077, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 65, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000075, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 66, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000069, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 67, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000062, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 68, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000057, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 69, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000051, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 70, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000048, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 71, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000046, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 72, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000040, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 73, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000038, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 74, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000035, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 75, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000033, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 76, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000031, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 77, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000028, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 78, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000025, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 79, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000024, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 80, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000023, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 81, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000022, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 82, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000019, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 83, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000018, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 84, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000016, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 85, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000015, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 86, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000014, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 87, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000013, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 88, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000012, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 89, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000012, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 90, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000011, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 91, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000010, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 92, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000009, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 93, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000008, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 94, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000008, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 95, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000007, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 96, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000006, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 97, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000006, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 98, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000006, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 99, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000006, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 100, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000005, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","Training stage finished:\n"," epoch 100, loss 0.0000, train acc 1.000, training time 81.64 s\n","\n","\n","====================Starting evaluation for testing set.========================\n","\n","confusion_matrix\n","[[ 5899     0     1     0     0     0     0     5     0]\n"," [    0 16597     0     1     0     0     0     0     0]\n"," [    0     0  1868    14     0     0     0     0     0]\n"," [    0     1     0  2712     0     0     0     0    12]\n"," [    0     0     0     0  1198     0     0     0     0]\n"," [    0     1     0     1     0  4477     0     0     0]\n"," [    0     0     0     0     0     0  1184     0     0]\n"," [    3     0     1     0     0     0     0  3273     0]\n"," [    0     0     0     0     0     0     0     0   832]]\n","                      precision    recall  f1-score   support\n","\n","             Asphalt       1.00      1.00      1.00      5902\n","             Meadows       1.00      1.00      1.00     16599\n","              Gravel       0.99      1.00      1.00      1870\n","               Trees       1.00      0.99      0.99      2728\n","Painted metal sheets       1.00      1.00      1.00      1198\n","           Bare Soil       1.00      1.00      1.00      4477\n","             Bitumen       1.00      1.00      1.00      1184\n","Self-Blocking Bricks       1.00      1.00      1.00      3278\n","             Shadows       1.00      0.99      0.99       844\n","\n","            accuracy                           1.00     38080\n","           macro avg       1.00      1.00      1.00     38080\n","        weighted avg       1.00      1.00      1.00     38080\n","\n","classification_report\n","                      precision    recall  f1-score   support\n","\n","             Asphalt       1.00      1.00      1.00      5902\n","             Meadows       1.00      1.00      1.00     16599\n","              Gravel       0.99      1.00      1.00      1870\n","               Trees       1.00      0.99      0.99      2728\n","Painted metal sheets       1.00      1.00      1.00      1198\n","           Bare Soil       1.00      1.00      1.00      4477\n","             Bitumen       1.00      1.00      1.00      1184\n","Self-Blocking Bricks       1.00      1.00      1.00      3278\n","             Shadows       1.00      0.99      0.99       844\n","\n","            accuracy                           1.00     38080\n","           macro avg       1.00      1.00      1.00     38080\n","        weighted avg       1.00      1.00      1.00     38080\n","\n","save model...\n","epoch: 1, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.381165, tarin loss sum: 51.076100, train acc: 0.888, train_acc_sum: 3796.0, time: 0.9 sec\n","save model...\n","epoch: 2, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.122805, tarin loss sum: 16.455858, train acc: 0.958, train_acc_sum: 4092.0, time: 0.8 sec\n","save model...\n","epoch: 3, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.063717, tarin loss sum: 8.538016, train acc: 0.980, train_acc_sum: 4188.0, time: 0.8 sec\n","save model...\n","epoch: 4, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.042059, tarin loss sum: 5.635883, train acc: 0.985, train_acc_sum: 4210.0, time: 0.8 sec\n","epoch: 5, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.018474, tarin loss sum: 2.475450, train acc: 0.993, train_acc_sum: 4245.0, time: 0.8 sec\n","epoch: 6, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.029210, tarin loss sum: 3.914172, train acc: 0.992, train_acc_sum: 4238.0, time: 0.8 sec\n","save model...\n","epoch: 7, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.049304, tarin loss sum: 6.606684, train acc: 0.983, train_acc_sum: 4199.0, time: 0.8 sec\n","save model...\n","epoch: 8, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.017220, tarin loss sum: 2.307445, train acc: 0.995, train_acc_sum: 4250.0, time: 0.8 sec\n","epoch: 9, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.001496, tarin loss sum: 0.200521, train acc: 1.000, train_acc_sum: 4271.0, time: 0.8 sec\n","save model...\n","epoch: 10, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.002771, tarin loss sum: 0.371307, train acc: 0.999, train_acc_sum: 4268.0, time: 0.8 sec\n","epoch: 11, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000262, tarin loss sum: 0.035089, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 12, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000170, tarin loss sum: 0.022836, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 13, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000129, tarin loss sum: 0.017288, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 14, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000097, tarin loss sum: 0.013029, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 15, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000082, tarin loss sum: 0.011013, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 16, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000069, tarin loss sum: 0.009276, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 17, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000059, tarin loss sum: 0.007897, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 18, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000052, tarin loss sum: 0.006920, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 19, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000044, tarin loss sum: 0.005918, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 20, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000039, tarin loss sum: 0.005255, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 21, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000035, tarin loss sum: 0.004671, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 22, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000030, tarin loss sum: 0.004084, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 23, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000027, tarin loss sum: 0.003648, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 24, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000024, tarin loss sum: 0.003197, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 25, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000022, tarin loss sum: 0.002981, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","save model...\n","epoch: 26, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000020, tarin loss sum: 0.002699, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 27, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000019, tarin loss sum: 0.002518, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 28, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000016, tarin loss sum: 0.002173, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 29, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000015, tarin loss sum: 0.001950, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 30, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000013, tarin loss sum: 0.001763, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 31, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000012, tarin loss sum: 0.001588, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 32, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000011, tarin loss sum: 0.001462, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 33, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000010, tarin loss sum: 0.001361, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 34, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000009, tarin loss sum: 0.001227, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 35, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000008, tarin loss sum: 0.001110, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 36, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000008, tarin loss sum: 0.001037, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 37, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000007, tarin loss sum: 0.000962, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 38, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000006, tarin loss sum: 0.000867, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 39, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000006, tarin loss sum: 0.000813, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 40, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000005, tarin loss sum: 0.000734, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 41, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000005, tarin loss sum: 0.000676, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 42, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000005, tarin loss sum: 0.000627, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 43, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000575, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 44, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000530, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 45, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000004, tarin loss sum: 0.000490, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 46, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000449, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 47, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000418, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 48, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000377, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 49, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000003, tarin loss sum: 0.000352, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 50, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000326, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 51, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000299, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 52, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000281, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 53, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000256, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 54, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000237, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 55, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000002, tarin loss sum: 0.000223, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 56, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000200, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 57, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000189, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 58, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000175, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 59, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000158, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 60, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000150, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 61, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000138, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 62, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000128, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 63, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000119, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 64, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000111, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 65, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000102, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 66, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000093, train acc: 1.000, train_acc_sum: 4273.0, time: 0.8 sec\n","epoch: 67, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000088, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 68, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000078, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 69, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000077, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 70, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000001, tarin loss sum: 0.000068, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 71, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000065, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 72, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000060, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 73, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000057, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 74, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000051, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 75, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000048, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 76, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000043, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 77, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000040, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 78, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000038, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 79, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000035, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 80, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000033, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 81, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000030, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 82, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000027, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 83, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000026, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 84, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000024, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 85, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000022, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 86, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000021, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 87, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000019, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 88, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000018, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 89, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000016, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 90, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000015, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 91, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000014, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 92, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000013, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 93, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000012, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 94, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000011, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 95, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000010, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 96, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000010, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 97, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000009, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 98, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000008, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 99, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000008, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","epoch: 100, training_sampler_num: 4273, batch_count: 134.00, train loss: 0.000000, tarin loss sum: 0.000007, train acc: 1.000, train_acc_sum: 4273.0, time: 0.9 sec\n","Training stage finished:\n"," epoch 100, loss 0.0000, train acc 1.000, training time 84.87 s\n","\n","\n","====================Starting evaluation for testing set.========================\n","\n","confusion_matrix\n","[[ 5898     0     2     1     0     0     1     0     0]\n"," [    0 16599     0     4     0     0     0     0     0]\n"," [    1     0  1842     0     0     0     0     0     0]\n"," [    0     0     0  2711     0     0     0     0     0]\n"," [    0     0     0     0  1192     0     0     0     0]\n"," [    0     0     0     0     0  4477     0     0     0]\n"," [    0     0     0     0     0     0  1183     0     0]\n"," [    3     0    26     0     0     0     0  3278     0]\n"," [    0     0     0    12     6     0     0     0   844]]\n","                      precision    recall  f1-score   support\n","\n","             Asphalt       1.00      1.00      1.00      5902\n","             Meadows       1.00      1.00      1.00     16599\n","              Gravel       1.00      0.99      0.99      1870\n","               Trees       1.00      0.99      1.00      2728\n","Painted metal sheets       1.00      0.99      1.00      1198\n","           Bare Soil       1.00      1.00      1.00      4477\n","             Bitumen       1.00      1.00      1.00      1184\n","Self-Blocking Bricks       0.99      1.00      1.00      3278\n","             Shadows       0.98      1.00      0.99       844\n","\n","            accuracy                           1.00     38080\n","           macro avg       1.00      1.00      1.00     38080\n","        weighted avg       1.00      1.00      1.00     38080\n","\n","classification_report\n","                      precision    recall  f1-score   support\n","\n","             Asphalt       1.00      1.00      1.00      5902\n","             Meadows       1.00      1.00      1.00     16599\n","              Gravel       1.00      0.99      0.99      1870\n","               Trees       1.00      0.99      1.00      2728\n","Painted metal sheets       1.00      0.99      1.00      1198\n","           Bare Soil       1.00      1.00      1.00      4477\n","             Bitumen       1.00      1.00      1.00      1184\n","Self-Blocking Bricks       0.99      1.00      1.00      3278\n","             Shadows       0.98      1.00      0.99       844\n","\n","            accuracy                           1.00     38080\n","           macro avg       1.00      1.00      1.00     38080\n","        weighted avg       1.00      1.00      1.00     38080\n","\n","\n","====================Mean result of 5 times runs =========================\n","List of OA: [0.9993172268907563, 0.9990546218487395, 0.9989495798319328, 0.9989495798319328, 0.9985294117647059]\n","List of AA: [0.9991541569922799, 0.9986372431238719, 0.9989614701692745, 0.9983385522061218, 0.996543089100245]\n","List of KPP: [0.9990953265360882, 0.9987474342265367, 0.9986082823407584, 0.9986082354482155, 0.9980514219092719]\n","OA= 99.9 +- 0.03\n","AA= 99.83 +- 0.09\n","Kpp= 99.86 +- 0.03\n","Acc per class= [ 99.93  99.98  99.83  99.85  99.93  99.93 100.    99.48  99.56] +- [0.02 0.02 0.29 0.18 0.06 0.11 0.   0.25 0.82]\n","Average training time= 83.57 +- 2.976\n","Average testing time= 1.81 +- 0.102\n"]}]}]}