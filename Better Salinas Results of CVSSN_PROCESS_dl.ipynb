{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1BgyV0cypQ1YlT0LAzUBsTpC1qduwj8yg","timestamp":1680562964028}],"gpuType":"A100","authorship_tag":"ABX9TyO6GQQBZympdjzx5mKjynzF"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"premium"},"cells":[{"cell_type":"markdown","source":["## -*- coding: utf-8 -*-\n","# @Auther   : Mingsong Li (lms-07)\n","# @Time     : 2022-Nov\n","# @Address  : Time Lab @ SDU\n","# @FileName : process_dl.py\n","# @Project  : CVSSN (HSIC), IEEE TCSVT\n","\n","# for IP, KSC, and UP data sets, main processing file for the involved deep learning models,\n","# i.e., ,\n","# ContextualNet, RSSAN, SSTN, SSAtt, SSAN, SSSAN, A2S2KResNet, and the proposed CVSSN\n","\n"],"metadata":{"id":"BrKQpn_RwoGW"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Yq6wLy5lwgOD","executionInfo":{"status":"ok","timestamp":1680570298524,"user_tz":300,"elapsed":19008,"user":{"displayName":"Michael Wesselink","userId":"03807820748818897534"}},"outputId":"e99df351-9ea3-4a67-bc43-2233527c3781"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive/\n"]}],"source":["#Original code attributed above from https://github.com/lms-07/CVSSN\n","\n","#Edits by Mike Wesselink 3.27.23\n","\n","###############################\n","#Mike Wesselink CIS 631\n","\n","#Mount my google drive (Plan B)\n","from google.colab import drive\n","drive.mount('/content/drive/',force_remount=True)"]},{"cell_type":"code","source":["#imports\n","\n","import os\n","import time\n","import torch\n","import random\n","import numpy as np\n","from sklearn import metrics\n","\n","!pip install thop\n","from thop import profile\n","\n","#import spectral\n","!pip install spectral\n","from spectral import *\n","\n","import sys\n","\n","py_file_location = \"/content/drive/MyDrive/Colab Notebooks/CIS 631 Final Project/CVSSN-main\"\n","sys.path.append(os.path.abspath(py_file_location))\n","\n","import utils.evaluation as evaluation\n","import utils.data_load_operate as data_load_operate\n","import visual.cls_map_visual as cls_visual\n","\n","import model.CVSSN as CVSSN\n","\n","#import model.ContextualNet as ContextualNet\n","#import model.RSSAN as RSSAN\n","#import model.SSTN as SSTN\n","#import model.SSAtt as SSAtt\n","#import model.A2S2KResNet as A2S2KResNet\n","#import model.SSAN as SSAN\n","#import model.SSSAN as SSSAN\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"3qGmG6xcwg1h","executionInfo":{"status":"ok","timestamp":1680570314352,"user_tz":300,"elapsed":15835,"user":{"displayName":"Michael Wesselink","userId":"03807820748818897534"}},"outputId":"8e21fff4-bf4c-4fe5-d380-6daa030237e9"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting thop\n","  Downloading thop-0.1.1.post2209072238-py3-none-any.whl (15 kB)\n","Requirement already satisfied: torch in /usr/local/lib/python3.9/dist-packages (from thop) (2.0.0+cu118)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.9/dist-packages (from torch->thop) (3.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.9/dist-packages (from torch->thop) (3.10.7)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.9/dist-packages (from torch->thop) (1.11.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.9/dist-packages (from torch->thop) (2.0.0)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.9/dist-packages (from torch->thop) (4.5.0)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.9/dist-packages (from torch->thop) (3.1.2)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->thop) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.9/dist-packages (from triton==2.0.0->torch->thop) (16.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.9/dist-packages (from jinja2->torch->thop) (2.1.2)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.9/dist-packages (from sympy->torch->thop) (1.3.0)\n","Installing collected packages: thop\n","Successfully installed thop-0.1.1.post2209072238\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting spectral\n","  Downloading spectral-0.23.1-py3-none-any.whl (212 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m212.9/212.9 KB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.9/dist-packages (from spectral) (1.22.4)\n","Installing collected packages: spectral\n","Successfully installed spectral-0.23.1\n"]}]},{"cell_type":"code","source":["#SET UP MODEL INFO\n","\n","time_current = time.strftime(\"%y-%m-%d-%H.%M\", time.localtime())\n","\n","# random seed setting\n","seed = 20\n","\n","torch.manual_seed(seed)\n","torch.cuda.manual_seed(seed)\n","torch.cuda.manual_seed_all(seed)\n","np.random.seed(seed)  # Numpy module.\n","random.seed(seed)  # Python random module.\n","torch.backends.cudnn.benchmark = False\n","torch.backends.cudnn.deterministic = True\n","\n","\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","###                 0             1       2       3        4        5         6             7\n","model_list = ['ContextualNet', 'RSSAN', 'SSTN', 'SSAN', 'SSSAN', 'SSAtt', 'A2S2KResNet', 'CVSSN']\n","\n","model_flag = 7      #use only the CVSSN model\n","model_spa_set = {1, 2, 3, 5}\n","model_spe_set = {}\n","model_spa_spe_set = {4, 7}\n","model_3D_spa_set = {0, 6}\n","\n","model_3D_spa_flag = 0\n","\n","if model_flag in model_spa_set:\n","    model_type_flag = 1\n","    if model_flag in model_3D_spa_set:\n","        model_3D_spa_flag = 1\n","elif model_flag in model_spe_set:\n","    model_type_flag = 2\n","elif model_flag in model_spa_spe_set:\n","    model_type_flag = 3\n","\n","# 0-3\n","#data_set_name_list = ['IP', 'KSC', 'UP', 'HU_tif']\n","data_set_name_list = ['IP', 'KSC', 'UP', 'Salinas']\n","data_set_name = data_set_name_list[3]  #>>>test all 4 data sets by selecting position in data_set_name_list above?<<<\n","\n","# seed_list = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9]  \n","seed_list=[0,1,2,3,4]\n","# seed_list=[0,1,2] \n","# seed_list=[0,1]\n","#seed_list = [0]  \n","\n","# ratio=0.5\n","# ratio=1.0\n","# ratio=2.5\n","# ratio=5.0\n","# ratio=7.5\n","ratio = 10.0\n","patch_size = 9\n","patch_length = 4\n","\n","\n","###SET UP DATA PATH###\n","\n","#data_set_path = os.path.join(os.getcwd(), 'data')\n","data_set_path = '/content/drive/MyDrive/Colab Notebooks/CIS 631 Final Project/CVSSN-main/data'\n","\n","#results_save_path = \\\n","#    os.path.join(os.getcwd(), 'output/results', model_list[model_flag] + str(\"_\") +\n","#                 data_set_name + str(\"_\") + str(time_current) + str(\"_seed\") + str(seed) + str(\"_ratio\") + str(\n","#        ratio) + str(\"_patch_size\") + str(patch_size))\n","\n","results_save_path = \\\n","    os.path.join('/content/drive/MyDrive/Colab Notebooks/CIS 631 Final Project/CVSSN-main/output/results', model_list[model_flag] + str(\"_\") +\n","                data_set_name + str(\"_\") + str(time_current) + str(\"_seed\") + str(seed) + str(\"_ratio\") + str(\n","        ratio) + str(\"_patch_size\") + str(patch_size))\n","\n","\n","#cls_map_save_path = \\\n","#    os.path.join(os.path.join(os.getcwd(), 'output/cls_maps'), model_list[model_flag] + str(\"_\") +\n","#                 data_set_name + str(\"_\") + str(time_current) + str(\"_seed\") + str(seed)) + str(\"_ratio\") + str(ratio)\n","\n","cls_map_save_path = \\\n","    os.path.join(os.path.join('/content/drive/MyDrive/Colab Notebooks/CIS 631 Final Project/CVSSN-main/output/cls_maps'), model_list[model_flag] + str(\"_\") +\n","                 data_set_name + str(\"_\") + str(time_current) + str(\"_seed\") + str(seed)) + str(\"_ratio\") + str(ratio)\n","\n","if __name__ == '__main__':\n","\n","    torch.cuda.empty_cache()\n","\n","    data, gt = data_load_operate.load_data(data_set_name, data_set_path)\n","\n","    height, width, channels = data.shape\n","\n","    data = data_load_operate.standardization(data)\n","\n","    gt_reshape = gt.reshape(-1)\n","    height, width, channels = data.shape\n","    class_count = max(np.unique(gt))\n","\n","    flag_list = [0, 1]  # ratio or num\n","    ratio_list = [0.1, 0.01]  # [train_ratio,val_ratio]\n","    # ratio_list=[0.075,0.0075] # [train_ratio,val_ratio]\n","    # ratio_list=[0.05,0.005] # [train_ratio,val_ratio]\n","    # ratio_list=[0.0255,0.0025] # [train_ratio,val_ratio]\n","    # ratio_list=[0.01,0.001] # [train_ratio,val_ratio]\n","    # ratio_list=[0.005,0.0005] # [train_ratio,val_ratio]\n","    num_list = [45, 4]  # [train_num,val_num]\n","\n","    batch_size = 32\n","    max_epoch = 100\n","    learning_rate = 0.001\n","    loss = torch.nn.CrossEntropyLoss()\n","\n","    # data pad zero\n","    # data:[h,w,c]->data_padded:[h+2l,w+2l,c]\n","    data_padded = data_load_operate.data_pad_zero(data, patch_length)\n","    height_patched, width_patched, channels = data_padded.shape\n","\n","    OA_ALL = []\n","    AA_ALL = []\n","    KPP_ALL = []\n","    EACH_ACC_ALL = []\n","    Train_Time_ALL = []\n","    Test_Time_ALL = []\n","    CLASS_ACC = np.zeros([len(seed_list), class_count])\n","\n","    # data_total_index = np.arange(data.shape[0] * data.shape[1])  # For total sample cls_map.\n","\n","    for curr_seed in seed_list:\n","\n","        train_data_index, val_data_index, test_data_index, all_data_index = data_load_operate.sampling(ratio_list,\n","                                                                                                       num_list,\n","                                                                                                       gt_reshape,\n","                                                                                                       class_count,\n","                                                                                                       flag_list[0])\n","        index = (train_data_index, val_data_index, test_data_index)\n","        train_iter, test_iter, val_iter = data_load_operate.generate_iter_1 \\\n","            (data_padded, height, width, gt_reshape, index, patch_length, batch_size, model_type_flag,\n","             model_3D_spa_flag)\n","\n","\n","\n","        # load data for the cls map of all the labed samples\n","        # all_iter = data_load_operate.generate_iter_2(data_padded, height, width, gt_reshape, all_data_index,\n","        #                                              patch_length,\n","        #                                              batch_size, model_type_flag, model_3D_spa_flag)\n","        # load data for the cls map of the total samples\n","        # total_iter = data_load_operate.generate_iter_2(data_padded,height, width, gt_reshape, data_total_index, patch_length,\n","        #              25, model_type_flag, model_3D_spa_flag)\n","\n","        if model_flag == 0:\n","            net = ContextualNet.LeeEtAl(channels, class_count)\n","        elif model_flag == 1:\n","            net = RSSAN.RSSAN_net(in_shape=(channels, height_patched, width_patched), num_classes=class_count)\n","        elif model_flag == 2:\n","            net = SSTN.SSTN_AEAE(in_shape=(channels, height_patched, width_patched), num_classes=class_count)\n","        elif model_flag == 3:\n","            net = SSAN.SSAN(channels, patch_size, class_count)\n","        elif model_flag == 4:\n","            net = SSSAN.SSSAN(channels, class_count)\n","        elif model_flag == 5:\n","            net = SSAtt.Hang2020(channels, class_count)\n","        elif model_flag == 6:\n","            net = A2S2KResNet.S3KAIResNet(channels, class_count, 2)\n","        elif model_flag == 7:\n","            net = CVSSN.CVSSN_(channels, patch_size, patch_size, class_count)\n","\n","        # efficiency test, model complexity and computational cost\n","        # test_spe_input=torch.randn(1,channels) # for 1D model\n","        # test_input=torch.randn(1,patch_size,patch_size,channels) # for 2D model\n","        # test_input=torch.randn(1,1,patch_size,patch_size,channels) # for 3D model\n","        #\n","        # flops,para=profile(net,(test_input,test_spe_input))\n","        # flops,para=profile(net,(test_spe_input))\n","        # flops,para=profile(net,(test_input))\n","        #\n","        # print(\"para:{}\\n,flops:{}\".format(para,flops))\n","        # print(\"para(M):{:.3f},\\n flops(M):{:.2f}\".format(para/(1000**2),flops/(1000**2),))\n","\n","        net.to(device)\n","\n","        train_loss_list = [100]\n","        train_acc_list = [0]\n","        val_loss_list = [100]\n","        val_acc_list = [0]\n","        optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n","        best_loss = 99999\n","\n","        tic1 = time.perf_counter()\n","\n","        for epoch in range(max_epoch):\n","            train_acc_sum, trained_samples_counter = 0.0, 0\n","            batch_counter, train_loss_sum = 0, 0\n","            time_epoch = time.time()\n","\n","            if model_type_flag == 1:  # data for single spatial net\n","                for X_spa, y in train_iter:\n","                    X_spa, y = X_spa.to(device), y.to(device)\n","                    y_pred = net(X_spa)\n","\n","                    ls = loss(y_pred, y.long())\n","\n","                    optimizer.zero_grad()\n","                    ls.backward()\n","                    optimizer.step()\n","\n","                    train_loss_sum += ls.cpu().item()\n","                    train_acc_sum += (y_pred.argmax(dim=1) == y).sum().cpu().item()\n","                    trained_samples_counter += y.shape[0]\n","                    batch_counter += 1\n","                    epoch_first_iter = 0\n","            elif model_type_flag == 2:  # data for single spectral net\n","                for X_spe, y in train_iter:\n","                    X_spe, y = X_spe.to(device), y.to(device)\n","                    y_pred = net(X_spe)\n","\n","                    ls = loss(y_pred, y.long())\n","\n","                    optimizer.zero_grad()\n","                    ls.backward()\n","                    optimizer.step()\n","\n","                    train_loss_sum += ls.cpu().item()\n","                    train_acc_sum += (y_pred.argmax(dim=1) == y).sum().cpu().item()\n","                    trained_samples_counter += y.shape[0]\n","                    batch_counter += 1\n","                    epoch_first_iter = 0\n","            elif model_type_flag == 3:  # data for spectral-spatial net\n","                for X_spa, X_spe, y in train_iter:\n","                    X_spa, X_spe, y = X_spa.to(device), X_spe.to(device), y.to(device)\n","                    y_pred = net(X_spa, X_spe)\n","                    if model_flag == 10:\n","                        for i in range(len(y_pred)):\n","                            if i == 0:\n","                                ls = loss(y_pred[i], y.long())\n","                            if i > 0:\n","                                ls += loss(y_pred[i], y.long())\n","                    else:\n","\n","                        ls = loss(y_pred, y.long())\n","\n","                    optimizer.zero_grad()\n","                    ls.backward()\n","                    optimizer.step()\n","\n","                    train_loss_sum += ls.cpu().item()\n","                    train_acc_sum += (y_pred.argmax(dim=1) == y).sum().cpu().item()\n","                    trained_samples_counter += y.shape[0]\n","                    batch_counter += 1\n","                    epoch_first_iter = 0\n","\n","            val_acc, val_loss = evaluation.evaluate_OA(val_iter, net, loss, device, model_type_flag)\n","            val_loss_list.append(val_loss)\n","            val_acc_list.append(val_acc)\n","\n","            if val_loss < best_loss:\n","                best_loss = val_loss\n","                torch.save(net.state_dict(), results_save_path + \"_best_model.pt\")\n","                print('save model...')\n","\n","            torch.cuda.empty_cache()\n","\n","            train_loss_list.append(train_loss_sum)\n","            train_acc_list.append(train_acc_sum / trained_samples_counter)\n","\n","            print('epoch: %d, training_sampler_num: %d, batch_count: %.2f, train loss: %.6f, tarin loss sum: %.6f, '\n","                  'train acc: %.3f, train_acc_sum: %.1f, time: %.1f sec' %\n","                  (epoch + 1, trained_samples_counter, batch_counter, train_loss_sum / batch_counter, train_loss_sum,\n","                   train_acc_sum / trained_samples_counter, train_acc_sum, time.time() - time_epoch))\n","\n","        toc1 = time.perf_counter()\n","        print('Training stage finished:\\n epoch %d, loss %.4f, train acc %.3f, training time %.2f s'\n","              % (epoch + 1, train_loss_sum / batch_counter, train_acc_sum / trained_samples_counter, toc1 - tic1))\n","        training_time = toc1 - tic1\n","        Train_Time_ALL.append(training_time)\n","\n","        print(\"\\n\\n====================Starting evaluation for testing set.========================\\n\")\n","\n","        pred_test = []\n","        # torch.cuda.empty_cache()\n","        with torch.no_grad():\n","            # net.load_state_dict(torch.load(model_save_path+\"_best_model.pt\"))\n","            net.eval()\n","            train_acc_sum, samples_num_counter = 0.0, 0\n","            if model_type_flag == 1:  # data for single spatial net\n","                for X_spa, y in test_iter:\n","                    X_spa = X_spa.to(device)\n","                    y = y.to(device)\n","\n","                    tic2 = time.perf_counter()\n","                    y_pred = net(X_spa)\n","                    toc2 = time.perf_counter()\n","\n","                    pred_test.extend(np.array(y_pred.cpu().argmax(axis=1)))\n","            elif model_type_flag == 2:  # data for single spectral net\n","                for X_spe, y in test_iter:\n","                    X_spe = X_spe.to(device)\n","                    y = y.to(device)\n","\n","                    tic2 = time.perf_counter()\n","                    y_pred = net(X_spe)\n","                    toc2 = time.perf_counter()\n","\n","                    pred_test.extend(np.array(y_pred.cpu().argmax(axis=1)))\n","            elif model_type_flag == 3:  # data for spectral-spatial net\n","                for X_spa, X_spe, y in test_iter:\n","                    X_spa = X_spa.to(device)\n","                    X_spe = X_spe.to(device)\n","                    y = y.to(device)\n","\n","                    tic2 = time.perf_counter()\n","                    y_pred = net(X_spa, X_spe)\n","                    toc2 = time.perf_counter()\n","\n","                    pred_test.extend(np.array(y_pred.cpu().argmax(axis=1)))\n","\n","            y_gt = gt_reshape[test_data_index] - 1\n","            OA = metrics.accuracy_score(y_gt, pred_test)\n","            confusion_matrix = metrics.confusion_matrix(pred_test, y_gt)\n","            print(\"confusion_matrix\\n{}\".format(confusion_matrix))\n","            ECA, AA = evaluation.AA_ECA(confusion_matrix)\n","            kappa = metrics.cohen_kappa_score(pred_test, y_gt)\n","            cls_report = evaluation.claification_report(y_gt, pred_test, data_set_name)\n","            print(\"classification_report\\n{}\".format(cls_report))\n","\n","            # Visualization for all the labeled samples and total the samples\n","            # sample_list1 = [all_iter, all_data_index]\n","            # sample_list2 = [total_iter]\n","\n","            # cls_visual.pred_cls_map_dl(sample_list1,net,gt,cls_map_save_path,model_type_flag)\n","            # cls_visual.pred_cls_map_dl(sample_list2, net, gt, cls_map_save_path,model_type_flag)\n","\n","            testing_time = toc2 - tic2\n","            Test_Time_ALL.append(testing_time)\n","\n","\n","            # Output infors\n","            f = open(results_save_path + '_results.txt', 'a+')\n","            str_results = '\\n======================' \\\n","                          + \" learning rate=\" + str(learning_rate) \\\n","                          + \" epochs=\" + str(max_epoch) \\\n","                          + \" train ratio=\" + str(ratio_list[0]) \\\n","                          + \" val ratio=\" + str(ratio_list[1]) \\\n","                          + \" ======================\" \\\n","                          + \"\\nOA=\" + str(OA) \\\n","                          + \"\\nAA=\" + str(AA) \\\n","                          + '\\nkpp=' + str(kappa) \\\n","                          + '\\nacc per class:' + str(ECA) \\\n","                          + \"\\ntrain time:\" + str(training_time) \\\n","                          + \"\\ntest time:\" + str(testing_time) + \"\\n\"\n","\n","            f.write(str_results)\n","            f.write('{}'.format(confusion_matrix))\n","            f.write('\\n\\n')\n","            f.write('{}'.format(cls_report))\n","            f.close()\n","\n","            OA_ALL.append(OA)\n","            AA_ALL.append(AA)\n","            KPP_ALL.append(kappa)\n","            EACH_ACC_ALL.append(ECA)\n","\n","        torch.cuda.empty_cache()\n","        del net, train_iter, test_iter, val_iter\n","        # del net, train_iter, test_iter, val_iter, all_iter\n","        # del net\n","\n","    OA_ALL = np.array(OA_ALL)\n","    AA_ALL = np.array(AA_ALL)\n","    KPP_ALL = np.array(KPP_ALL)\n","    EACH_ACC_ALL = np.array(EACH_ACC_ALL)\n","    Train_Time_ALL = np.array(Train_Time_ALL)\n","    Test_Time_ALL = np.array(Test_Time_ALL)\n","\n","    np.set_printoptions(precision=4)\n","    print(\"\\n====================Mean result of {} times runs =========================\".format(len(seed_list)))\n","    print('List of OA:', list(OA_ALL))\n","    print('List of AA:', list(AA_ALL))\n","    print('List of KPP:', list(KPP_ALL))\n","    print('OA=', round(np.mean(OA_ALL) * 100, 2), '+-', round(np.std(OA_ALL) * 100, 2))\n","    print('AA=', round(np.mean(AA_ALL) * 100, 2), '+-', round(np.std(AA_ALL) * 100, 2))\n","    print('Kpp=', round(np.mean(KPP_ALL) * 100, 2), '+-', round(np.std(KPP_ALL) * 100, 2))\n","    print('Acc per class=', np.round(np.mean(EACH_ACC_ALL, 0) * 100, decimals=2), '+-',\n","          np.round(np.std(EACH_ACC_ALL, 0) * 100, decimals=2))\n","\n","    print(\"Average training time=\", round(np.mean(Train_Time_ALL), 2), '+-', round(np.std(Train_Time_ALL), 3))\n","    print(\"Average testing time=\", round(np.mean(Test_Time_ALL) * 1000, 2), '+-',\n","          round(np.std(Test_Time_ALL) * 1000, 3))\n","\n","    # Output infors\n","    f = open(results_save_path + '_results.txt', 'a+')\n","    str_results = '\\n\\n***************Mean result of ' + str(len(seed_list)) + 'times runs ********************' \\\n","                  + '\\nList of OA:' + str(list(OA_ALL)) \\\n","                  + '\\nList of AA:' + str(list(AA_ALL)) \\\n","                  + '\\nList of KPP:' + str(list(KPP_ALL)) \\\n","                  + '\\nOA=' + str(round(np.mean(OA_ALL) * 100, 2)) + '+-' + str(round(np.std(OA_ALL) * 100, 2)) \\\n","                  + '\\nAA=' + str(round(np.mean(AA_ALL) * 100, 2)) + '+-' + str(round(np.std(AA_ALL) * 100, 2)) \\\n","                  + '\\nKpp=' + str(round(np.mean(KPP_ALL) * 100, 2)) + '+-' + str(round(np.std(KPP_ALL) * 100, 2)) \\\n","                  + '\\nAcc per class=\\n' + str(np.round(np.mean(EACH_ACC_ALL, 0) * 100, 2)) + '+-' + str(\n","        np.round(np.std(EACH_ACC_ALL, 0) * 100, 2)) \\\n","                  + \"\\nAverage training time=\" + str(np.round(np.mean(Train_Time_ALL), decimals=2)) + '+-' + str(\n","        np.round(np.std(Train_Time_ALL), decimals=3)) \\\n","                  + \"\\nAverage testing time=\" + str(np.round(np.mean(Test_Time_ALL) * 1000, decimals=2)) + '+-' + str(\n","        np.round(np.std(Test_Time_ALL) * 100, decimals=3))\n","    f.write(str_results)\n","    f.close()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ATgpQ1R56bW9","executionInfo":{"status":"ok","timestamp":1680570885172,"user_tz":300,"elapsed":570833,"user":{"displayName":"Michael Wesselink","userId":"03807820748818897534"}},"outputId":"b61c9e65-c45b-4258-c531-c4b6f6eae99d"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["save model...\n","epoch: 1, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.561334, tarin loss sum: 94.865453, train acc: 0.820, train_acc_sum: 4431.0, time: 9.0 sec\n","save model...\n","epoch: 2, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.329409, tarin loss sum: 55.670116, train acc: 0.898, train_acc_sum: 4850.0, time: 1.0 sec\n","epoch: 3, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.101514, tarin loss sum: 17.155856, train acc: 0.963, train_acc_sum: 5204.0, time: 1.1 sec\n","save model...\n","epoch: 4, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.080329, tarin loss sum: 13.575666, train acc: 0.971, train_acc_sum: 5249.0, time: 1.0 sec\n","epoch: 5, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.056399, tarin loss sum: 9.531450, train acc: 0.977, train_acc_sum: 5281.0, time: 1.0 sec\n","save model...\n","epoch: 6, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.048167, tarin loss sum: 8.140222, train acc: 0.980, train_acc_sum: 5295.0, time: 1.0 sec\n","save model...\n","epoch: 7, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.033941, tarin loss sum: 5.736063, train acc: 0.989, train_acc_sum: 5342.0, time: 1.0 sec\n","save model...\n","epoch: 8, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.030047, tarin loss sum: 5.077864, train acc: 0.989, train_acc_sum: 5343.0, time: 1.0 sec\n","epoch: 9, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.230501, tarin loss sum: 38.954731, train acc: 0.948, train_acc_sum: 5121.0, time: 1.0 sec\n","epoch: 10, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.040070, tarin loss sum: 6.771911, train acc: 0.983, train_acc_sum: 5310.0, time: 1.0 sec\n","save model...\n","epoch: 11, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.018342, tarin loss sum: 3.099802, train acc: 0.995, train_acc_sum: 5378.0, time: 1.1 sec\n","epoch: 12, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.019048, tarin loss sum: 3.219057, train acc: 0.993, train_acc_sum: 5367.0, time: 1.0 sec\n","save model...\n","epoch: 13, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.038014, tarin loss sum: 6.424389, train acc: 0.986, train_acc_sum: 5327.0, time: 1.0 sec\n","epoch: 14, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.011085, tarin loss sum: 1.873319, train acc: 0.996, train_acc_sum: 5382.0, time: 1.0 sec\n","save model...\n","epoch: 15, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.005264, tarin loss sum: 0.889589, train acc: 0.999, train_acc_sum: 5396.0, time: 1.0 sec\n","epoch: 16, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000753, tarin loss sum: 0.127333, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 17, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000411, tarin loss sum: 0.069516, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 18, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000309, tarin loss sum: 0.052260, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 19, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000226, tarin loss sum: 0.038250, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","save model...\n","epoch: 20, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000147, tarin loss sum: 0.024906, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 21, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000135, tarin loss sum: 0.022841, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 22, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000110, tarin loss sum: 0.018601, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 23, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000094, tarin loss sum: 0.015865, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 24, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000081, tarin loss sum: 0.013613, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 25, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000067, tarin loss sum: 0.011293, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 26, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000063, tarin loss sum: 0.010708, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 27, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000051, tarin loss sum: 0.008650, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 28, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000045, tarin loss sum: 0.007677, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 29, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000043, tarin loss sum: 0.007314, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 30, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000037, tarin loss sum: 0.006175, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 31, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000030, tarin loss sum: 0.005149, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 32, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000027, tarin loss sum: 0.004589, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 33, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000024, tarin loss sum: 0.004086, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 34, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000021, tarin loss sum: 0.003561, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 35, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000020, tarin loss sum: 0.003349, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 36, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000017, tarin loss sum: 0.002903, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 37, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000015, tarin loss sum: 0.002543, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","save model...\n","epoch: 38, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000013, tarin loss sum: 0.002238, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 39, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000012, tarin loss sum: 0.002074, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 40, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000011, tarin loss sum: 0.001874, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 41, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000009, tarin loss sum: 0.001587, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 42, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000009, tarin loss sum: 0.001465, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 43, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000007, tarin loss sum: 0.001252, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 44, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000008, tarin loss sum: 0.001297, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 45, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000006, tarin loss sum: 0.001023, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 46, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000006, tarin loss sum: 0.000935, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 47, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000005, tarin loss sum: 0.000834, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 48, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000004, tarin loss sum: 0.000729, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 49, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000004, tarin loss sum: 0.000698, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 50, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000004, tarin loss sum: 0.000609, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 51, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000552, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 52, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000477, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 53, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000471, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 54, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000432, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 55, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000357, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 56, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000319, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 57, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000290, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 58, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000269, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 59, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000234, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 60, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000217, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","save model...\n","epoch: 61, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000197, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 62, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000164, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 63, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000173, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 64, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000142, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 65, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000118, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 66, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000111, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 67, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000099, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 68, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000087, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 69, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000082, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 70, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000069, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 71, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000063, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 72, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000059, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 73, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000052, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 74, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000048, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 75, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000044, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 76, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000037, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 77, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000035, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 78, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000033, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 79, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.275801, tarin loss sum: 46.610299, train acc: 0.967, train_acc_sum: 5225.0, time: 1.0 sec\n","epoch: 80, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.252753, tarin loss sum: 42.715205, train acc: 0.919, train_acc_sum: 4968.0, time: 1.0 sec\n","epoch: 81, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.077326, tarin loss sum: 13.068049, train acc: 0.970, train_acc_sum: 5240.0, time: 1.0 sec\n","epoch: 82, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.036266, tarin loss sum: 6.128886, train acc: 0.986, train_acc_sum: 5327.0, time: 1.0 sec\n","epoch: 83, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.018144, tarin loss sum: 3.066360, train acc: 0.994, train_acc_sum: 5370.0, time: 1.0 sec\n","epoch: 84, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.017571, tarin loss sum: 2.969501, train acc: 0.993, train_acc_sum: 5367.0, time: 1.0 sec\n","epoch: 85, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.020141, tarin loss sum: 3.403846, train acc: 0.993, train_acc_sum: 5365.0, time: 1.0 sec\n","epoch: 86, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.014501, tarin loss sum: 2.450649, train acc: 0.995, train_acc_sum: 5378.0, time: 1.0 sec\n","epoch: 87, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.020970, tarin loss sum: 3.543975, train acc: 0.994, train_acc_sum: 5370.0, time: 1.0 sec\n","epoch: 88, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.001784, tarin loss sum: 0.301441, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 89, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000553, tarin loss sum: 0.093518, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 90, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000279, tarin loss sum: 0.047212, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 91, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000199, tarin loss sum: 0.033686, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 92, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000145, tarin loss sum: 0.024462, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 93, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000110, tarin loss sum: 0.018511, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 94, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000089, tarin loss sum: 0.015002, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 95, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000076, tarin loss sum: 0.012819, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 96, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000063, tarin loss sum: 0.010673, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 97, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000054, tarin loss sum: 0.009136, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 98, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000051, tarin loss sum: 0.008539, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 99, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000041, tarin loss sum: 0.006890, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 100, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000038, tarin loss sum: 0.006388, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","Training stage finished:\n"," epoch 100, loss 0.0000, train acc 1.000, training time 111.31 s\n","\n","\n","====================Starting evaluation for testing set.========================\n","\n","confusion_matrix\n","[[1789    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0 3317    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0 1756    0    0    0    0    0    0    3    0    0    0    0\n","     0    0]\n"," [   0    0    0 1237    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    4    5 2385    0    0    0    3    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0 3525    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0 3185    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0 9941    0    0    1    0    0    0\n","    80   17]\n"," [   0    0    0    0    0    0    0    0 5518    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    1    0 2916    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0  951    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0 1716    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0  816    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0  953\n","     0    0]\n"," [   0    0    0    0    0    0    0   90    0    0    0    0    0    0\n","  6390    0]\n"," [   0    0    0    0    0    0    2    0    0    0    0    0    0    0\n","     0 1592]]\n","                            precision    recall  f1-score   support\n","\n","     Brocoli_green_weeds_1       1.00      1.00      1.00      1789\n","      Brocoli_gree_weeds_2       1.00      1.00      1.00      3317\n","                    Fallow       1.00      1.00      1.00      1760\n","         Fallow_rough_plow       1.00      1.00      1.00      1242\n","             Fallow_smooth       0.99      1.00      1.00      2385\n","                   Stubble       1.00      1.00      1.00      3525\n","                    Celery       1.00      1.00      1.00      3187\n","          Grapes_untrained       0.99      0.99      0.99     10032\n","      Soil_vinyard_develop       1.00      1.00      1.00      5521\n","Corn_sensesced_green_weeds       1.00      1.00      1.00      2919\n","       Lettuce_romaine_4wk       1.00      1.00      1.00       952\n","       Lettuce_romaine_5wk       1.00      1.00      1.00      1716\n","       Lettuce_romaine_6wk       1.00      1.00      1.00       816\n","       Lettuce_romaine_7wk       1.00      1.00      1.00       953\n","         Vinyard_untrained       0.99      0.99      0.99      6470\n","  Vinyard_vertical_trellis       1.00      0.99      0.99      1609\n","\n","                  accuracy                           1.00     48193\n","                 macro avg       1.00      1.00      1.00     48193\n","              weighted avg       1.00      1.00      1.00     48193\n","\n","classification_report\n","                            precision    recall  f1-score   support\n","\n","     Brocoli_green_weeds_1       1.00      1.00      1.00      1789\n","      Brocoli_gree_weeds_2       1.00      1.00      1.00      3317\n","                    Fallow       1.00      1.00      1.00      1760\n","         Fallow_rough_plow       1.00      1.00      1.00      1242\n","             Fallow_smooth       0.99      1.00      1.00      2385\n","                   Stubble       1.00      1.00      1.00      3525\n","                    Celery       1.00      1.00      1.00      3187\n","          Grapes_untrained       0.99      0.99      0.99     10032\n","      Soil_vinyard_develop       1.00      1.00      1.00      5521\n","Corn_sensesced_green_weeds       1.00      1.00      1.00      2919\n","       Lettuce_romaine_4wk       1.00      1.00      1.00       952\n","       Lettuce_romaine_5wk       1.00      1.00      1.00      1716\n","       Lettuce_romaine_6wk       1.00      1.00      1.00       816\n","       Lettuce_romaine_7wk       1.00      1.00      1.00       953\n","         Vinyard_untrained       0.99      0.99      0.99      6470\n","  Vinyard_vertical_trellis       1.00      0.99      0.99      1609\n","\n","                  accuracy                           1.00     48193\n","                 macro avg       1.00      1.00      1.00     48193\n","              weighted avg       1.00      1.00      1.00     48193\n","\n","save model...\n","epoch: 1, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.502246, tarin loss sum: 84.879501, train acc: 0.842, train_acc_sum: 4551.0, time: 1.2 sec\n","save model...\n","epoch: 2, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.244554, tarin loss sum: 41.329660, train acc: 0.911, train_acc_sum: 4924.0, time: 1.0 sec\n","epoch: 3, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.123746, tarin loss sum: 20.913027, train acc: 0.954, train_acc_sum: 5156.0, time: 1.0 sec\n","save model...\n","epoch: 4, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.067373, tarin loss sum: 11.386006, train acc: 0.975, train_acc_sum: 5267.0, time: 1.0 sec\n","epoch: 5, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.146502, tarin loss sum: 24.758762, train acc: 0.953, train_acc_sum: 5151.0, time: 1.0 sec\n","save model...\n","epoch: 6, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.063426, tarin loss sum: 10.718980, train acc: 0.974, train_acc_sum: 5265.0, time: 1.0 sec\n","epoch: 7, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.042371, tarin loss sum: 7.160762, train acc: 0.982, train_acc_sum: 5307.0, time: 1.1 sec\n","epoch: 8, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.027678, tarin loss sum: 4.677504, train acc: 0.990, train_acc_sum: 5349.0, time: 1.1 sec\n","epoch: 9, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.050430, tarin loss sum: 8.522609, train acc: 0.980, train_acc_sum: 5294.0, time: 1.0 sec\n","epoch: 10, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.017685, tarin loss sum: 2.988721, train acc: 0.994, train_acc_sum: 5371.0, time: 1.0 sec\n","epoch: 11, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.018655, tarin loss sum: 3.152619, train acc: 0.992, train_acc_sum: 5362.0, time: 1.0 sec\n","epoch: 12, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.057659, tarin loss sum: 9.744309, train acc: 0.982, train_acc_sum: 5305.0, time: 1.0 sec\n","epoch: 13, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.120652, tarin loss sum: 20.390186, train acc: 0.969, train_acc_sum: 5237.0, time: 1.0 sec\n","epoch: 14, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.020147, tarin loss sum: 3.404823, train acc: 0.994, train_acc_sum: 5369.0, time: 1.0 sec\n","save model...\n","epoch: 15, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.008679, tarin loss sum: 1.466808, train acc: 0.997, train_acc_sum: 5387.0, time: 1.0 sec\n","epoch: 16, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.005192, tarin loss sum: 0.877482, train acc: 0.998, train_acc_sum: 5394.0, time: 1.0 sec\n","epoch: 17, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.001308, tarin loss sum: 0.221106, train acc: 1.000, train_acc_sum: 5402.0, time: 1.0 sec\n","epoch: 18, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000651, tarin loss sum: 0.109954, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 19, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000271, tarin loss sum: 0.045878, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 20, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000206, tarin loss sum: 0.034865, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 21, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000150, tarin loss sum: 0.025415, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 22, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000150, tarin loss sum: 0.025434, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 23, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000108, tarin loss sum: 0.018216, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 24, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000088, tarin loss sum: 0.014788, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 25, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000080, tarin loss sum: 0.013477, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 26, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000066, tarin loss sum: 0.011221, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 27, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000057, tarin loss sum: 0.009705, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 28, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000051, tarin loss sum: 0.008602, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 29, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000045, tarin loss sum: 0.007634, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 30, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000040, tarin loss sum: 0.006678, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 31, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000035, tarin loss sum: 0.005949, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 32, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000030, tarin loss sum: 0.005070, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 33, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000028, tarin loss sum: 0.004774, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 34, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000024, tarin loss sum: 0.004092, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 35, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000022, tarin loss sum: 0.003653, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 36, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000020, tarin loss sum: 0.003351, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 37, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000017, tarin loss sum: 0.002949, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 38, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000015, tarin loss sum: 0.002597, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 39, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000014, tarin loss sum: 0.002369, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 40, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000012, tarin loss sum: 0.002059, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 41, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000012, tarin loss sum: 0.002067, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 42, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000010, tarin loss sum: 0.001677, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 43, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000009, tarin loss sum: 0.001440, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 44, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000008, tarin loss sum: 0.001355, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 45, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000007, tarin loss sum: 0.001255, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 46, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000006, tarin loss sum: 0.001086, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 47, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000006, tarin loss sum: 0.001017, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 48, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000005, tarin loss sum: 0.000886, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 49, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000005, tarin loss sum: 0.000778, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 50, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000004, tarin loss sum: 0.000703, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 51, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000004, tarin loss sum: 0.000597, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 52, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000570, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 53, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000522, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 54, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000459, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 55, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000459, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 56, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000381, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 57, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000325, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 58, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000318, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 59, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000268, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 60, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000252, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 61, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000228, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 62, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000219, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 63, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000183, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 64, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000169, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 65, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000150, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 66, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000135, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 67, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000131, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 68, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000117, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 69, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000097, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 70, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000090, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 71, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000078, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 72, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000074, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 73, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000074, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 74, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000062, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 75, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000055, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 76, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000048, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 77, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000044, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 78, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000039, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 79, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000039, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 80, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000034, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 81, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000029, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 82, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000026, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 83, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000025, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 84, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000022, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 85, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000020, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 86, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000018, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 87, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000017, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 88, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000015, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 89, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000013, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 90, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000013, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 91, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000012, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 92, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000011, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 93, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000009, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 94, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000008, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 95, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000008, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 96, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000006, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 97, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000006, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 98, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000006, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 99, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000005, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 100, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000006, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","Training stage finished:\n"," epoch 100, loss 0.0000, train acc 1.000, training time 103.63 s\n","\n","\n","====================Starting evaluation for testing set.========================\n","\n","confusion_matrix\n","[[1789    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0 3317    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0 1760    0    0    0    0    0    0    2    0    0    0    0\n","     0    0]\n"," [   0    0    0 1239    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    1 2382    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0 3525    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0 3187    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0 9994    0    0    1    0    0    0\n","     8    0]\n"," [   0    0    0    0    0    0    0    0 5521    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    2    3    0    0    0    0 2917    4    0    0    7\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0  942    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0 1716    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0  816    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0  946\n","     0    0]\n"," [   0    0    0    0    0    0    0   38    0    0    5    0    0    0\n","  6462    2]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0 1607]]\n","                            precision    recall  f1-score   support\n","\n","     Brocoli_green_weeds_1       1.00      1.00      1.00      1789\n","      Brocoli_gree_weeds_2       1.00      1.00      1.00      3317\n","                    Fallow       1.00      1.00      1.00      1760\n","         Fallow_rough_plow       1.00      1.00      1.00      1242\n","             Fallow_smooth       1.00      1.00      1.00      2385\n","                   Stubble       1.00      1.00      1.00      3525\n","                    Celery       1.00      1.00      1.00      3187\n","          Grapes_untrained       1.00      1.00      1.00     10032\n","      Soil_vinyard_develop       1.00      1.00      1.00      5521\n","Corn_sensesced_green_weeds       0.99      1.00      1.00      2919\n","       Lettuce_romaine_4wk       1.00      0.99      0.99       952\n","       Lettuce_romaine_5wk       1.00      1.00      1.00      1716\n","       Lettuce_romaine_6wk       1.00      1.00      1.00       816\n","       Lettuce_romaine_7wk       1.00      0.99      1.00       953\n","         Vinyard_untrained       0.99      1.00      1.00      6470\n","  Vinyard_vertical_trellis       1.00      1.00      1.00      1609\n","\n","                  accuracy                           1.00     48193\n","                 macro avg       1.00      1.00      1.00     48193\n","              weighted avg       1.00      1.00      1.00     48193\n","\n","classification_report\n","                            precision    recall  f1-score   support\n","\n","     Brocoli_green_weeds_1       1.00      1.00      1.00      1789\n","      Brocoli_gree_weeds_2       1.00      1.00      1.00      3317\n","                    Fallow       1.00      1.00      1.00      1760\n","         Fallow_rough_plow       1.00      1.00      1.00      1242\n","             Fallow_smooth       1.00      1.00      1.00      2385\n","                   Stubble       1.00      1.00      1.00      3525\n","                    Celery       1.00      1.00      1.00      3187\n","          Grapes_untrained       1.00      1.00      1.00     10032\n","      Soil_vinyard_develop       1.00      1.00      1.00      5521\n","Corn_sensesced_green_weeds       0.99      1.00      1.00      2919\n","       Lettuce_romaine_4wk       1.00      0.99      0.99       952\n","       Lettuce_romaine_5wk       1.00      1.00      1.00      1716\n","       Lettuce_romaine_6wk       1.00      1.00      1.00       816\n","       Lettuce_romaine_7wk       1.00      0.99      1.00       953\n","         Vinyard_untrained       0.99      1.00      1.00      6470\n","  Vinyard_vertical_trellis       1.00      1.00      1.00      1609\n","\n","                  accuracy                           1.00     48193\n","                 macro avg       1.00      1.00      1.00     48193\n","              weighted avg       1.00      1.00      1.00     48193\n","\n","save model...\n","epoch: 1, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.508878, tarin loss sum: 86.000399, train acc: 0.828, train_acc_sum: 4472.0, time: 1.1 sec\n","save model...\n","epoch: 2, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.300556, tarin loss sum: 50.793988, train acc: 0.909, train_acc_sum: 4909.0, time: 1.1 sec\n","save model...\n","epoch: 3, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.143055, tarin loss sum: 24.176323, train acc: 0.950, train_acc_sum: 5134.0, time: 1.1 sec\n","save model...\n","epoch: 4, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.081022, tarin loss sum: 13.692731, train acc: 0.972, train_acc_sum: 5254.0, time: 1.1 sec\n","epoch: 5, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.094307, tarin loss sum: 15.937961, train acc: 0.962, train_acc_sum: 5197.0, time: 1.0 sec\n","epoch: 6, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.048955, tarin loss sum: 8.273344, train acc: 0.981, train_acc_sum: 5299.0, time: 1.0 sec\n","epoch: 7, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.058100, tarin loss sum: 9.818936, train acc: 0.978, train_acc_sum: 5284.0, time: 1.0 sec\n","save model...\n","epoch: 8, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.119187, tarin loss sum: 20.142608, train acc: 0.963, train_acc_sum: 5205.0, time: 1.1 sec\n","epoch: 9, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.052897, tarin loss sum: 8.939664, train acc: 0.981, train_acc_sum: 5302.0, time: 1.0 sec\n","save model...\n","epoch: 10, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.020723, tarin loss sum: 3.502205, train acc: 0.992, train_acc_sum: 5360.0, time: 1.0 sec\n","save model...\n","epoch: 11, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.014935, tarin loss sum: 2.523997, train acc: 0.996, train_acc_sum: 5381.0, time: 1.1 sec\n","epoch: 12, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.038077, tarin loss sum: 6.434954, train acc: 0.987, train_acc_sum: 5331.0, time: 1.1 sec\n","save model...\n","epoch: 13, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.009588, tarin loss sum: 1.620378, train acc: 0.997, train_acc_sum: 5388.0, time: 1.1 sec\n","epoch: 14, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.005590, tarin loss sum: 0.944794, train acc: 0.999, train_acc_sum: 5395.0, time: 1.1 sec\n","epoch: 15, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.018112, tarin loss sum: 3.060849, train acc: 0.994, train_acc_sum: 5369.0, time: 1.0 sec\n","epoch: 16, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.203504, tarin loss sum: 34.392179, train acc: 0.942, train_acc_sum: 5091.0, time: 1.0 sec\n","epoch: 17, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.038376, tarin loss sum: 6.485504, train acc: 0.987, train_acc_sum: 5331.0, time: 1.1 sec\n","epoch: 18, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.020563, tarin loss sum: 3.475137, train acc: 0.992, train_acc_sum: 5360.0, time: 1.1 sec\n","epoch: 19, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.005800, tarin loss sum: 0.980167, train acc: 0.998, train_acc_sum: 5394.0, time: 1.1 sec\n","epoch: 20, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.005353, tarin loss sum: 0.904642, train acc: 0.999, train_acc_sum: 5395.0, time: 1.0 sec\n","epoch: 21, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.001233, tarin loss sum: 0.208341, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 22, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000467, tarin loss sum: 0.078871, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 23, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000290, tarin loss sum: 0.049008, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 24, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000233, tarin loss sum: 0.039358, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 25, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000166, tarin loss sum: 0.028130, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","save model...\n","epoch: 26, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000134, tarin loss sum: 0.022604, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 27, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000121, tarin loss sum: 0.020487, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 28, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000102, tarin loss sum: 0.017202, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 29, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000085, tarin loss sum: 0.014418, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 30, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000073, tarin loss sum: 0.012382, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 31, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000060, tarin loss sum: 0.010162, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 32, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000058, tarin loss sum: 0.009720, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","save model...\n","epoch: 33, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000049, tarin loss sum: 0.008293, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 34, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000041, tarin loss sum: 0.006997, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 35, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000039, tarin loss sum: 0.006529, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 36, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000032, tarin loss sum: 0.005376, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 37, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000029, tarin loss sum: 0.004936, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 38, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000024, tarin loss sum: 0.004128, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 39, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000022, tarin loss sum: 0.003754, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 40, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000021, tarin loss sum: 0.003471, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 41, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000017, tarin loss sum: 0.002870, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 42, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000016, tarin loss sum: 0.002671, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 43, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000014, tarin loss sum: 0.002373, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 44, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000013, tarin loss sum: 0.002113, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 45, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000012, tarin loss sum: 0.001954, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 46, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000010, tarin loss sum: 0.001663, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 47, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000009, tarin loss sum: 0.001516, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 48, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000009, tarin loss sum: 0.001469, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 49, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000007, tarin loss sum: 0.001238, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 50, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000006, tarin loss sum: 0.001089, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 51, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000006, tarin loss sum: 0.001078, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 52, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000005, tarin loss sum: 0.000920, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 53, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000005, tarin loss sum: 0.000767, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 54, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000005, tarin loss sum: 0.000785, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 55, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000004, tarin loss sum: 0.000625, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 56, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000588, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 57, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000524, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 58, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000449, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 59, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000437, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 60, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000434, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 61, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000345, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 62, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000320, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 63, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000262, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 64, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000240, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 65, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000219, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 66, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000200, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 67, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000174, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 68, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000174, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 69, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000147, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 70, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000137, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 71, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000127, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 72, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000097, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 73, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000095, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 74, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000183, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 75, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.290721, tarin loss sum: 49.131884, train acc: 0.938, train_acc_sum: 5070.0, time: 1.0 sec\n","epoch: 76, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.093056, tarin loss sum: 15.726421, train acc: 0.969, train_acc_sum: 5235.0, time: 1.0 sec\n","epoch: 77, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.036458, tarin loss sum: 6.161404, train acc: 0.987, train_acc_sum: 5331.0, time: 1.1 sec\n","epoch: 78, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.011787, tarin loss sum: 1.992056, train acc: 0.996, train_acc_sum: 5383.0, time: 1.1 sec\n","epoch: 79, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.008502, tarin loss sum: 1.436835, train acc: 0.997, train_acc_sum: 5389.0, time: 1.0 sec\n","epoch: 80, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.005328, tarin loss sum: 0.900438, train acc: 0.999, train_acc_sum: 5397.0, time: 1.0 sec\n","epoch: 81, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000590, tarin loss sum: 0.099699, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 82, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000287, tarin loss sum: 0.048567, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 83, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000194, tarin loss sum: 0.032836, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 84, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000143, tarin loss sum: 0.024100, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 85, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000119, tarin loss sum: 0.020195, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 86, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000098, tarin loss sum: 0.016538, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 87, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000077, tarin loss sum: 0.012975, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 88, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000064, tarin loss sum: 0.010761, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 89, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000059, tarin loss sum: 0.010022, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 90, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000050, tarin loss sum: 0.008374, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 91, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000042, tarin loss sum: 0.007166, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 92, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000036, tarin loss sum: 0.006112, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 93, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000032, tarin loss sum: 0.005452, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 94, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000029, tarin loss sum: 0.004884, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 95, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000026, tarin loss sum: 0.004428, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 96, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000022, tarin loss sum: 0.003786, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 97, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000021, tarin loss sum: 0.003478, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 98, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000018, tarin loss sum: 0.003065, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 99, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000016, tarin loss sum: 0.002706, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 100, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000014, tarin loss sum: 0.002418, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","Training stage finished:\n"," epoch 100, loss 0.0000, train acc 1.000, training time 103.86 s\n","\n","\n","====================Starting evaluation for testing set.========================\n","\n","confusion_matrix\n","[[1789    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0 3317    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0 1760    0    0    0    0    0    0    5    0    0    0    0\n","     0    0]\n"," [   0    0    0 1238    0    0    0    0    0    0    0    0    0    0\n","     1    0]\n"," [   0    0    0    4 2383    0    0    0    0    0    0    0    0    1\n","     0    0]\n"," [   0    0    0    0    0 3525    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0 3187    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0 9980    0    0    0    0    0    0\n","   129    0]\n"," [   0    0    0    0    0    0    0    0 5519    1    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    2    0    0    0    1 2913    0    0    0    2\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    1    0  952    3    0    1\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0 1713    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0  816    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0  949\n","     0    0]\n"," [   0    0    0    0    0    0    0   52    0    0    0    0    0    0\n","  6340    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0 1609]]\n","                            precision    recall  f1-score   support\n","\n","     Brocoli_green_weeds_1       1.00      1.00      1.00      1789\n","      Brocoli_gree_weeds_2       1.00      1.00      1.00      3317\n","                    Fallow       1.00      1.00      1.00      1760\n","         Fallow_rough_plow       1.00      1.00      1.00      1242\n","             Fallow_smooth       1.00      1.00      1.00      2385\n","                   Stubble       1.00      1.00      1.00      3525\n","                    Celery       1.00      1.00      1.00      3187\n","          Grapes_untrained       0.99      0.99      0.99     10032\n","      Soil_vinyard_develop       1.00      1.00      1.00      5521\n","Corn_sensesced_green_weeds       1.00      1.00      1.00      2919\n","       Lettuce_romaine_4wk       0.99      1.00      1.00       952\n","       Lettuce_romaine_5wk       1.00      1.00      1.00      1716\n","       Lettuce_romaine_6wk       1.00      1.00      1.00       816\n","       Lettuce_romaine_7wk       1.00      1.00      1.00       953\n","         Vinyard_untrained       0.99      0.98      0.99      6470\n","  Vinyard_vertical_trellis       1.00      1.00      1.00      1609\n","\n","                  accuracy                           1.00     48193\n","                 macro avg       1.00      1.00      1.00     48193\n","              weighted avg       1.00      1.00      1.00     48193\n","\n","classification_report\n","                            precision    recall  f1-score   support\n","\n","     Brocoli_green_weeds_1       1.00      1.00      1.00      1789\n","      Brocoli_gree_weeds_2       1.00      1.00      1.00      3317\n","                    Fallow       1.00      1.00      1.00      1760\n","         Fallow_rough_plow       1.00      1.00      1.00      1242\n","             Fallow_smooth       1.00      1.00      1.00      2385\n","                   Stubble       1.00      1.00      1.00      3525\n","                    Celery       1.00      1.00      1.00      3187\n","          Grapes_untrained       0.99      0.99      0.99     10032\n","      Soil_vinyard_develop       1.00      1.00      1.00      5521\n","Corn_sensesced_green_weeds       1.00      1.00      1.00      2919\n","       Lettuce_romaine_4wk       0.99      1.00      1.00       952\n","       Lettuce_romaine_5wk       1.00      1.00      1.00      1716\n","       Lettuce_romaine_6wk       1.00      1.00      1.00       816\n","       Lettuce_romaine_7wk       1.00      1.00      1.00       953\n","         Vinyard_untrained       0.99      0.98      0.99      6470\n","  Vinyard_vertical_trellis       1.00      1.00      1.00      1609\n","\n","                  accuracy                           1.00     48193\n","                 macro avg       1.00      1.00      1.00     48193\n","              weighted avg       1.00      1.00      1.00     48193\n","\n","save model...\n","epoch: 1, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.517941, tarin loss sum: 87.532032, train acc: 0.833, train_acc_sum: 4502.0, time: 1.1 sec\n","save model...\n","epoch: 2, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.219261, tarin loss sum: 37.055063, train acc: 0.919, train_acc_sum: 4966.0, time: 1.0 sec\n","epoch: 3, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.103351, tarin loss sum: 17.466392, train acc: 0.961, train_acc_sum: 5191.0, time: 1.0 sec\n","epoch: 4, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.071002, tarin loss sum: 11.999419, train acc: 0.974, train_acc_sum: 5264.0, time: 1.0 sec\n","save model...\n","epoch: 5, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.053572, tarin loss sum: 9.053600, train acc: 0.980, train_acc_sum: 5293.0, time: 1.1 sec\n","epoch: 6, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.066009, tarin loss sum: 11.155548, train acc: 0.979, train_acc_sum: 5292.0, time: 1.0 sec\n","epoch: 7, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.073604, tarin loss sum: 12.439093, train acc: 0.975, train_acc_sum: 5270.0, time: 1.1 sec\n","epoch: 8, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.195933, tarin loss sum: 33.112606, train acc: 0.937, train_acc_sum: 5065.0, time: 1.0 sec\n","epoch: 9, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.029601, tarin loss sum: 5.002521, train acc: 0.989, train_acc_sum: 5343.0, time: 1.0 sec\n","save model...\n","epoch: 10, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.032930, tarin loss sum: 5.565112, train acc: 0.991, train_acc_sum: 5353.0, time: 1.1 sec\n","epoch: 11, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.037576, tarin loss sum: 6.350428, train acc: 0.986, train_acc_sum: 5325.0, time: 1.1 sec\n","save model...\n","epoch: 12, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.008172, tarin loss sum: 1.381046, train acc: 0.998, train_acc_sum: 5391.0, time: 1.1 sec\n","epoch: 13, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.010175, tarin loss sum: 1.719620, train acc: 0.996, train_acc_sum: 5380.0, time: 1.0 sec\n","epoch: 14, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.016819, tarin loss sum: 2.842340, train acc: 0.995, train_acc_sum: 5374.0, time: 1.0 sec\n","epoch: 15, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.005118, tarin loss sum: 0.864950, train acc: 0.999, train_acc_sum: 5395.0, time: 1.1 sec\n","epoch: 16, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.002743, tarin loss sum: 0.463623, train acc: 0.999, train_acc_sum: 5400.0, time: 1.0 sec\n","epoch: 17, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.022753, tarin loss sum: 3.845271, train acc: 0.993, train_acc_sum: 5366.0, time: 1.0 sec\n","epoch: 18, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.011077, tarin loss sum: 1.871999, train acc: 0.997, train_acc_sum: 5385.0, time: 1.1 sec\n","epoch: 19, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.082373, tarin loss sum: 13.921103, train acc: 0.978, train_acc_sum: 5285.0, time: 1.0 sec\n","epoch: 20, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.047513, tarin loss sum: 8.029645, train acc: 0.985, train_acc_sum: 5321.0, time: 1.0 sec\n","epoch: 21, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.010367, tarin loss sum: 1.752021, train acc: 0.997, train_acc_sum: 5386.0, time: 1.0 sec\n","save model...\n","epoch: 22, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.002928, tarin loss sum: 0.494851, train acc: 0.999, train_acc_sum: 5398.0, time: 1.0 sec\n","epoch: 23, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000631, tarin loss sum: 0.106610, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 24, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000210, tarin loss sum: 0.035511, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 25, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000154, tarin loss sum: 0.025946, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 26, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000118, tarin loss sum: 0.019883, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 27, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000092, tarin loss sum: 0.015476, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 28, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000079, tarin loss sum: 0.013374, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 29, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000070, tarin loss sum: 0.011820, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 30, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000059, tarin loss sum: 0.009963, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 31, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000052, tarin loss sum: 0.008736, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 32, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000048, tarin loss sum: 0.008105, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 33, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000042, tarin loss sum: 0.007179, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 34, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000035, tarin loss sum: 0.005986, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 35, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000032, tarin loss sum: 0.005397, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 36, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000029, tarin loss sum: 0.004889, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 37, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000026, tarin loss sum: 0.004445, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 38, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000023, tarin loss sum: 0.003935, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 39, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000020, tarin loss sum: 0.003410, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 40, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000019, tarin loss sum: 0.003197, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 41, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000017, tarin loss sum: 0.002905, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 42, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000016, tarin loss sum: 0.002640, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 43, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000014, tarin loss sum: 0.002309, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 44, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000012, tarin loss sum: 0.002082, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 45, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000011, tarin loss sum: 0.001886, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 46, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000010, tarin loss sum: 0.001749, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 47, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000009, tarin loss sum: 0.001582, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 48, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000008, tarin loss sum: 0.001404, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 49, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000008, tarin loss sum: 0.001315, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 50, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000007, tarin loss sum: 0.001167, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 51, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000006, tarin loss sum: 0.001029, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 52, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000006, tarin loss sum: 0.000965, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 53, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000006, tarin loss sum: 0.000937, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","save model...\n","epoch: 54, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000005, tarin loss sum: 0.000826, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 55, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000004, tarin loss sum: 0.000691, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 56, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000004, tarin loss sum: 0.000642, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 57, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000004, tarin loss sum: 0.000594, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 58, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000572, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 59, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000509, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 60, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000448, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 61, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000392, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 62, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000355, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 63, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000342, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 64, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000297, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 65, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000260, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 66, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000245, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 67, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000223, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 68, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000201, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 69, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000187, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 70, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000167, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 71, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000153, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 72, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000130, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 73, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000120, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 74, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000116, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 75, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000104, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 76, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000093, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 77, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000082, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 78, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000074, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 79, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000067, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 80, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000059, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 81, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000054, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 82, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000048, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 83, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000049, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 84, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000043, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 85, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000037, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 86, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000034, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 87, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000030, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 88, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000028, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 89, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000025, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 90, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000022, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 91, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000020, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 92, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000020, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 93, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000017, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 94, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000015, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 95, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000014, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 96, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000012, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 97, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000012, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 98, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000010, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 99, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000010, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 100, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000009, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","Training stage finished:\n"," epoch 100, loss 0.0000, train acc 1.000, training time 103.92 s\n","\n","\n","====================Starting evaluation for testing set.========================\n","\n","confusion_matrix\n","[[1789    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0 3317    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0 1760    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0 1241    0    0    0    0    0    0    4    0    0    0\n","     0    0]\n"," [   0    0    0    1 2385    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0 3525    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0 3187    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0 9993    0    0    0    0    0    0\n","    49    0]\n"," [   0    0    0    0    0    0    0    0 5519    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    4    1 2919    1    0    0    7\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    1    0  947    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0 1716    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0  816    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0  946\n","     0    0]\n"," [   0    0    0    0    0    0    0   35    0    0    0    0    0    0\n","  6421    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0 1609]]\n","                            precision    recall  f1-score   support\n","\n","     Brocoli_green_weeds_1       1.00      1.00      1.00      1789\n","      Brocoli_gree_weeds_2       1.00      1.00      1.00      3317\n","                    Fallow       1.00      1.00      1.00      1760\n","         Fallow_rough_plow       1.00      1.00      1.00      1242\n","             Fallow_smooth       1.00      1.00      1.00      2385\n","                   Stubble       1.00      1.00      1.00      3525\n","                    Celery       1.00      1.00      1.00      3187\n","          Grapes_untrained       1.00      1.00      1.00     10032\n","      Soil_vinyard_develop       1.00      1.00      1.00      5521\n","Corn_sensesced_green_weeds       1.00      1.00      1.00      2919\n","       Lettuce_romaine_4wk       1.00      0.99      1.00       952\n","       Lettuce_romaine_5wk       1.00      1.00      1.00      1716\n","       Lettuce_romaine_6wk       1.00      1.00      1.00       816\n","       Lettuce_romaine_7wk       1.00      0.99      1.00       953\n","         Vinyard_untrained       0.99      0.99      0.99      6470\n","  Vinyard_vertical_trellis       1.00      1.00      1.00      1609\n","\n","                  accuracy                           1.00     48193\n","                 macro avg       1.00      1.00      1.00     48193\n","              weighted avg       1.00      1.00      1.00     48193\n","\n","classification_report\n","                            precision    recall  f1-score   support\n","\n","     Brocoli_green_weeds_1       1.00      1.00      1.00      1789\n","      Brocoli_gree_weeds_2       1.00      1.00      1.00      3317\n","                    Fallow       1.00      1.00      1.00      1760\n","         Fallow_rough_plow       1.00      1.00      1.00      1242\n","             Fallow_smooth       1.00      1.00      1.00      2385\n","                   Stubble       1.00      1.00      1.00      3525\n","                    Celery       1.00      1.00      1.00      3187\n","          Grapes_untrained       1.00      1.00      1.00     10032\n","      Soil_vinyard_develop       1.00      1.00      1.00      5521\n","Corn_sensesced_green_weeds       1.00      1.00      1.00      2919\n","       Lettuce_romaine_4wk       1.00      0.99      1.00       952\n","       Lettuce_romaine_5wk       1.00      1.00      1.00      1716\n","       Lettuce_romaine_6wk       1.00      1.00      1.00       816\n","       Lettuce_romaine_7wk       1.00      0.99      1.00       953\n","         Vinyard_untrained       0.99      0.99      0.99      6470\n","  Vinyard_vertical_trellis       1.00      1.00      1.00      1609\n","\n","                  accuracy                           1.00     48193\n","                 macro avg       1.00      1.00      1.00     48193\n","              weighted avg       1.00      1.00      1.00     48193\n","\n","save model...\n","epoch: 1, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.540599, tarin loss sum: 91.361147, train acc: 0.830, train_acc_sum: 4484.0, time: 1.1 sec\n","save model...\n","epoch: 2, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.267876, tarin loss sum: 45.271048, train acc: 0.899, train_acc_sum: 4856.0, time: 1.0 sec\n","epoch: 3, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.114675, tarin loss sum: 19.380037, train acc: 0.962, train_acc_sum: 5200.0, time: 1.0 sec\n","epoch: 4, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.087898, tarin loss sum: 14.854714, train acc: 0.968, train_acc_sum: 5230.0, time: 1.0 sec\n","save model...\n","epoch: 5, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.066889, tarin loss sum: 11.304324, train acc: 0.973, train_acc_sum: 5257.0, time: 1.1 sec\n","epoch: 6, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.063885, tarin loss sum: 10.796624, train acc: 0.976, train_acc_sum: 5276.0, time: 1.1 sec\n","epoch: 7, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.024621, tarin loss sum: 4.160940, train acc: 0.991, train_acc_sum: 5352.0, time: 1.0 sec\n","epoch: 8, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.034631, tarin loss sum: 5.852606, train acc: 0.989, train_acc_sum: 5344.0, time: 1.0 sec\n","save model...\n","epoch: 9, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.045542, tarin loss sum: 7.696573, train acc: 0.983, train_acc_sum: 5313.0, time: 1.0 sec\n","save model...\n","epoch: 10, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.012262, tarin loss sum: 2.072348, train acc: 0.997, train_acc_sum: 5388.0, time: 1.0 sec\n","epoch: 11, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.058077, tarin loss sum: 9.815009, train acc: 0.989, train_acc_sum: 5345.0, time: 1.0 sec\n","epoch: 12, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.272184, tarin loss sum: 45.999096, train acc: 0.947, train_acc_sum: 5119.0, time: 1.0 sec\n","epoch: 13, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.024818, tarin loss sum: 4.194242, train acc: 0.990, train_acc_sum: 5348.0, time: 1.0 sec\n","epoch: 14, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.067375, tarin loss sum: 11.386391, train acc: 0.983, train_acc_sum: 5309.0, time: 1.0 sec\n","save model...\n","epoch: 15, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.009177, tarin loss sum: 1.550858, train acc: 0.997, train_acc_sum: 5388.0, time: 1.1 sec\n","epoch: 16, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.001503, tarin loss sum: 0.254032, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 17, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000673, tarin loss sum: 0.113695, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 18, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.029816, tarin loss sum: 5.038943, train acc: 0.993, train_acc_sum: 5366.0, time: 1.1 sec\n","epoch: 19, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.040823, tarin loss sum: 6.899050, train acc: 0.987, train_acc_sum: 5333.0, time: 1.0 sec\n","epoch: 20, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.044597, tarin loss sum: 7.536946, train acc: 0.986, train_acc_sum: 5325.0, time: 1.0 sec\n","epoch: 21, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.006467, tarin loss sum: 1.092840, train acc: 0.999, train_acc_sum: 5396.0, time: 1.0 sec\n","epoch: 22, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.035682, tarin loss sum: 6.030206, train acc: 0.992, train_acc_sum: 5360.0, time: 1.0 sec\n","save model...\n","epoch: 23, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.015306, tarin loss sum: 2.586738, train acc: 0.995, train_acc_sum: 5375.0, time: 1.0 sec\n","epoch: 24, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.009892, tarin loss sum: 1.671802, train acc: 0.996, train_acc_sum: 5381.0, time: 1.0 sec\n","epoch: 25, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000583, tarin loss sum: 0.098594, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 26, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000246, tarin loss sum: 0.041532, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 27, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000170, tarin loss sum: 0.028814, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 28, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000134, tarin loss sum: 0.022646, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 29, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000106, tarin loss sum: 0.017863, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 30, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000091, tarin loss sum: 0.015337, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 31, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000074, tarin loss sum: 0.012576, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 32, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000064, tarin loss sum: 0.010848, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 33, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000059, tarin loss sum: 0.009907, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 34, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000048, tarin loss sum: 0.008176, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 35, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000045, tarin loss sum: 0.007526, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 36, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000038, tarin loss sum: 0.006500, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 37, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000034, tarin loss sum: 0.005742, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 38, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000031, tarin loss sum: 0.005320, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 39, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000027, tarin loss sum: 0.004594, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 40, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000024, tarin loss sum: 0.004126, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 41, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000022, tarin loss sum: 0.003664, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 42, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000020, tarin loss sum: 0.003376, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 43, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000017, tarin loss sum: 0.002948, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 44, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000016, tarin loss sum: 0.002721, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 45, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000014, tarin loss sum: 0.002447, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 46, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000013, tarin loss sum: 0.002213, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 47, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000012, tarin loss sum: 0.001948, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 48, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000011, tarin loss sum: 0.001785, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 49, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000010, tarin loss sum: 0.001665, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 50, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000009, tarin loss sum: 0.001444, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 51, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000008, tarin loss sum: 0.001346, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 52, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000007, tarin loss sum: 0.001160, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 53, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000006, tarin loss sum: 0.001083, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 54, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000006, tarin loss sum: 0.000980, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 55, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000005, tarin loss sum: 0.000900, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 56, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000005, tarin loss sum: 0.000800, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 57, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000004, tarin loss sum: 0.000742, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 58, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000004, tarin loss sum: 0.000668, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 59, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000588, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 60, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000544, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 61, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000490, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 62, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000003, tarin loss sum: 0.000468, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 63, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000404, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","save model...\n","epoch: 64, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000378, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 65, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000339, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 66, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000308, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 67, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000267, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 68, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000002, tarin loss sum: 0.000255, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 69, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000234, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 70, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000212, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 71, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000183, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 72, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000170, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 73, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000169, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 74, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000143, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 75, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000128, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 76, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000115, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 77, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000104, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 78, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000101, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 79, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000001, tarin loss sum: 0.000091, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 80, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000078, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 81, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000070, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 82, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000064, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 83, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000061, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 84, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000053, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 85, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000049, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 86, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000044, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 87, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000041, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 88, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000036, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 89, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000033, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","epoch: 90, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000031, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 91, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000028, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 92, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000026, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 93, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000024, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 94, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000021, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 95, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000020, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","save model...\n","epoch: 96, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000017, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 97, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000016, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 98, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000015, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 99, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000013, train acc: 1.000, train_acc_sum: 5403.0, time: 1.0 sec\n","epoch: 100, training_sampler_num: 5403, batch_count: 169.00, train loss: 0.000000, tarin loss sum: 0.000012, train acc: 1.000, train_acc_sum: 5403.0, time: 1.1 sec\n","Training stage finished:\n"," epoch 100, loss 0.0000, train acc 1.000, training time 103.89 s\n","\n","\n","====================Starting evaluation for testing set.========================\n","\n","confusion_matrix\n","[[1789    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0 3317    0    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0 1760    0    0    0    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0 1237    0    0    0    0    0    0    4    0    0    0\n","     0    0]\n"," [   0    0    0    5 2383    1    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0 3524    0    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0 3187    0    0    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0 9932    0    0    0    0    0    0\n","    80    0]\n"," [   0    0    0    0    0    0    0    0 5521    0    0    0    0    0\n","     0    0]\n"," [   0    0    0    0    2    0    0    0    0 2919    0    0    0    1\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0  948    0    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0 1716    0    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0  816    0\n","     0    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0  952\n","     0    0]\n"," [   0    0    0    0    0    0    0  100    0    0    0    0    0    0\n","  6390    0]\n"," [   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n","     0 1609]]\n","                            precision    recall  f1-score   support\n","\n","     Brocoli_green_weeds_1       1.00      1.00      1.00      1789\n","      Brocoli_gree_weeds_2       1.00      1.00      1.00      3317\n","                    Fallow       1.00      1.00      1.00      1760\n","         Fallow_rough_plow       1.00      1.00      1.00      1242\n","             Fallow_smooth       1.00      1.00      1.00      2385\n","                   Stubble       1.00      1.00      1.00      3525\n","                    Celery       1.00      1.00      1.00      3187\n","          Grapes_untrained       0.99      0.99      0.99     10032\n","      Soil_vinyard_develop       1.00      1.00      1.00      5521\n","Corn_sensesced_green_weeds       1.00      1.00      1.00      2919\n","       Lettuce_romaine_4wk       1.00      1.00      1.00       952\n","       Lettuce_romaine_5wk       1.00      1.00      1.00      1716\n","       Lettuce_romaine_6wk       1.00      1.00      1.00       816\n","       Lettuce_romaine_7wk       1.00      1.00      1.00       953\n","         Vinyard_untrained       0.98      0.99      0.99      6470\n","  Vinyard_vertical_trellis       1.00      1.00      1.00      1609\n","\n","                  accuracy                           1.00     48193\n","                 macro avg       1.00      1.00      1.00     48193\n","              weighted avg       1.00      1.00      1.00     48193\n","\n","classification_report\n","                            precision    recall  f1-score   support\n","\n","     Brocoli_green_weeds_1       1.00      1.00      1.00      1789\n","      Brocoli_gree_weeds_2       1.00      1.00      1.00      3317\n","                    Fallow       1.00      1.00      1.00      1760\n","         Fallow_rough_plow       1.00      1.00      1.00      1242\n","             Fallow_smooth       1.00      1.00      1.00      2385\n","                   Stubble       1.00      1.00      1.00      3525\n","                    Celery       1.00      1.00      1.00      3187\n","          Grapes_untrained       0.99      0.99      0.99     10032\n","      Soil_vinyard_develop       1.00      1.00      1.00      5521\n","Corn_sensesced_green_weeds       1.00      1.00      1.00      2919\n","       Lettuce_romaine_4wk       1.00      1.00      1.00       952\n","       Lettuce_romaine_5wk       1.00      1.00      1.00      1716\n","       Lettuce_romaine_6wk       1.00      1.00      1.00       816\n","       Lettuce_romaine_7wk       1.00      1.00      1.00       953\n","         Vinyard_untrained       0.98      0.99      0.99      6470\n","  Vinyard_vertical_trellis       1.00      1.00      1.00      1609\n","\n","                  accuracy                           1.00     48193\n","                 macro avg       1.00      1.00      1.00     48193\n","              weighted avg       1.00      1.00      1.00     48193\n","\n","\n","====================Mean result of 5 times runs =========================\n","List of OA: [0.9957255203037786, 0.9984852571950283, 0.9957877700080925, 0.9978627601518892, 0.9959952690224722]\n","List of AA: [0.9980024929503173, 0.999073422646681, 0.9978906772913998, 0.9987861582280022, 0.9981149909857503]\n","List of KPP: [0.9952403839950823, 0.9983134505472904, 0.9953093262034338, 0.9976202712160454, 0.9955410990873498]\n","OA= 99.68 +- 0.12\n","AA= 99.84 +- 0.05\n","Kpp= 99.64 +- 0.13\n","Acc per class= [100.   100.    99.89  99.86  99.79 100.   100.    99.27 100.    99.74\n","  99.87 100.   100.   100.    99.    99.97] +- [0.   0.   0.11 0.15 0.17 0.   0.   0.41 0.01 0.2  0.2  0.   0.   0.\n"," 0.4  0.05]\n","Average training time= 105.32 +- 2.994\n","Average testing time= 7.29 +- 10.519\n"]}]}]}